{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZv_yzJOHNqk"
   },
   "source": [
    "## Work\n",
    "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
    "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFzHDZi4HNqm"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3333,
     "status": "ok",
     "timestamp": 1574577229245,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "U2mohfxGHNqp",
    "outputId": "52006d9f-615b-4702-eaca-d26ff284552b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16384,
     "status": "ok",
     "timestamp": 1574577249626,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "mg3QtZuvHNqr",
    "outputId": "01b3d002-144d-4d6b-dbff-cb1d1e9e48dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9r4nUteMHNqt"
   },
   "outputs": [],
   "source": [
    "# 將 X 與 Y 獨立放進變數\n",
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "# 資料前處理 - 標準化\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "x_test = x_test.reshape((len(x_test), -1))\n",
    "\n",
    "# 將目標轉為 one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1574577263426,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "psOMeEm7HNqv",
    "outputId": "cc83ed19-b0dc-4c53-c677-eedd07b4b9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_mlp():\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
    "    x = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
    "    x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(units=64 , activation=\"relu\")(x)\n",
    "    out = keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "\n",
    "    return model\n",
    "model = build_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1574577277891,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "s59CFpi4HNqw",
    "outputId": "2118bc99-9035-4cf5-b77c-3ce9733f4e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,746,506\n",
      "Trainable params: 1,746,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 用 Keras 內建方法檢視模型各層參數量\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Va4e4lwPHNqz"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compile 模型\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 956087,
     "status": "ok",
     "timestamp": 1574578241489,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "knKZuuT4HNq0",
    "outputId": "03b95b17-2ae4-493c-befa-97f037a16dae",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.9519 - acc: 0.2874 - val_loss: 1.8239 - val_acc: 0.3373\n",
      "Epoch 2/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.7167 - acc: 0.3826 - val_loss: 1.7201 - val_acc: 0.3826\n",
      "Epoch 3/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.6366 - acc: 0.4128 - val_loss: 1.5607 - val_acc: 0.4488\n",
      "Epoch 4/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.5704 - acc: 0.4379 - val_loss: 1.5437 - val_acc: 0.4526\n",
      "Epoch 5/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.5144 - acc: 0.4579 - val_loss: 1.5341 - val_acc: 0.4518\n",
      "Epoch 6/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.4813 - acc: 0.4697 - val_loss: 1.4894 - val_acc: 0.4754\n",
      "Epoch 7/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.4363 - acc: 0.4852 - val_loss: 1.5134 - val_acc: 0.4591\n",
      "Epoch 8/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.4071 - acc: 0.4976 - val_loss: 1.4725 - val_acc: 0.4741\n",
      "Epoch 9/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.3800 - acc: 0.5060 - val_loss: 1.4096 - val_acc: 0.4999\n",
      "Epoch 10/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.3596 - acc: 0.5139 - val_loss: 1.4248 - val_acc: 0.4971\n",
      "Epoch 11/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 1.3346 - acc: 0.5223 - val_loss: 1.4178 - val_acc: 0.4998\n",
      "Epoch 12/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.3106 - acc: 0.5299 - val_loss: 1.4297 - val_acc: 0.4932\n",
      "Epoch 13/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.2842 - acc: 0.5411 - val_loss: 1.4210 - val_acc: 0.5022\n",
      "Epoch 14/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 1.2529 - acc: 0.5531 - val_loss: 1.3935 - val_acc: 0.5123\n",
      "Epoch 15/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.2276 - acc: 0.5584 - val_loss: 1.3922 - val_acc: 0.5104\n",
      "Epoch 16/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.2090 - acc: 0.5672 - val_loss: 1.4174 - val_acc: 0.5032\n",
      "Epoch 17/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.1863 - acc: 0.5758 - val_loss: 1.3609 - val_acc: 0.5254\n",
      "Epoch 18/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.1658 - acc: 0.5816 - val_loss: 1.3890 - val_acc: 0.5169\n",
      "Epoch 19/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 1.1503 - acc: 0.5892 - val_loss: 1.3973 - val_acc: 0.5079\n",
      "Epoch 20/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.1257 - acc: 0.5980 - val_loss: 1.3750 - val_acc: 0.5179\n",
      "Epoch 21/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.1013 - acc: 0.6058 - val_loss: 1.3918 - val_acc: 0.5160\n",
      "Epoch 22/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.0803 - acc: 0.6135 - val_loss: 1.3610 - val_acc: 0.5222\n",
      "Epoch 23/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.0639 - acc: 0.6199 - val_loss: 1.3903 - val_acc: 0.5186\n",
      "Epoch 24/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 1.0494 - acc: 0.6234 - val_loss: 1.3858 - val_acc: 0.5227\n",
      "Epoch 25/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 1.0259 - acc: 0.6291 - val_loss: 1.3898 - val_acc: 0.5213\n",
      "Epoch 26/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.0125 - acc: 0.6360 - val_loss: 1.3950 - val_acc: 0.5247\n",
      "Epoch 27/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.9965 - acc: 0.6415 - val_loss: 1.4436 - val_acc: 0.5148\n",
      "Epoch 28/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.9889 - acc: 0.6451 - val_loss: 1.4315 - val_acc: 0.5222\n",
      "Epoch 29/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.9466 - acc: 0.6619 - val_loss: 1.4301 - val_acc: 0.5198\n",
      "Epoch 30/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.9424 - acc: 0.6623 - val_loss: 1.4516 - val_acc: 0.5162\n",
      "Epoch 31/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.9262 - acc: 0.6670 - val_loss: 1.4566 - val_acc: 0.5214\n",
      "Epoch 32/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.9036 - acc: 0.6766 - val_loss: 1.4679 - val_acc: 0.5254\n",
      "Epoch 33/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.8901 - acc: 0.6796 - val_loss: 1.4770 - val_acc: 0.5231\n",
      "Epoch 34/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.8766 - acc: 0.6850 - val_loss: 1.5187 - val_acc: 0.5232\n",
      "Epoch 35/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.8579 - acc: 0.6912 - val_loss: 1.4982 - val_acc: 0.5260\n",
      "Epoch 36/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.8411 - acc: 0.6961 - val_loss: 1.5345 - val_acc: 0.5172\n",
      "Epoch 37/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.8271 - acc: 0.7033 - val_loss: 1.6049 - val_acc: 0.5100\n",
      "Epoch 38/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.8214 - acc: 0.7057 - val_loss: 1.5380 - val_acc: 0.5165\n",
      "Epoch 39/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.7900 - acc: 0.7153 - val_loss: 1.5560 - val_acc: 0.5214\n",
      "Epoch 40/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.7732 - acc: 0.7221 - val_loss: 1.5819 - val_acc: 0.5193\n",
      "Epoch 41/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.7747 - acc: 0.7220 - val_loss: 1.6168 - val_acc: 0.5200\n",
      "Epoch 42/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.7500 - acc: 0.7296 - val_loss: 1.6125 - val_acc: 0.5220\n",
      "Epoch 43/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.7333 - acc: 0.7356 - val_loss: 1.6410 - val_acc: 0.5207\n",
      "Epoch 44/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.7227 - acc: 0.7397 - val_loss: 1.6926 - val_acc: 0.5118\n",
      "Epoch 45/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.7198 - acc: 0.7402 - val_loss: 1.7287 - val_acc: 0.5162\n",
      "Epoch 46/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.6895 - acc: 0.7522 - val_loss: 1.7250 - val_acc: 0.5172\n",
      "Epoch 47/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.6786 - acc: 0.7564 - val_loss: 1.7862 - val_acc: 0.5080\n",
      "Epoch 48/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.6723 - acc: 0.7572 - val_loss: 1.7630 - val_acc: 0.5174\n",
      "Epoch 49/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.6540 - acc: 0.7648 - val_loss: 1.7957 - val_acc: 0.5136\n",
      "Epoch 50/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.6361 - acc: 0.7701 - val_loss: 1.8255 - val_acc: 0.5117\n",
      "Epoch 51/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.6288 - acc: 0.7742 - val_loss: 1.7986 - val_acc: 0.5175\n",
      "Epoch 52/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.6179 - acc: 0.7758 - val_loss: 1.8838 - val_acc: 0.5163\n",
      "Epoch 53/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.6179 - acc: 0.7773 - val_loss: 1.8793 - val_acc: 0.5219\n",
      "Epoch 54/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.5889 - acc: 0.7891 - val_loss: 1.9450 - val_acc: 0.5102\n",
      "Epoch 55/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.5998 - acc: 0.7828 - val_loss: 1.9878 - val_acc: 0.5098\n",
      "Epoch 56/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5740 - acc: 0.7933 - val_loss: 1.9391 - val_acc: 0.5123\n",
      "Epoch 57/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5729 - acc: 0.7939 - val_loss: 1.9980 - val_acc: 0.5064\n",
      "Epoch 58/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.5556 - acc: 0.8007 - val_loss: 2.0885 - val_acc: 0.5123\n",
      "Epoch 59/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.5383 - acc: 0.8057 - val_loss: 2.0486 - val_acc: 0.5103\n",
      "Epoch 60/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.5307 - acc: 0.8097 - val_loss: 2.1169 - val_acc: 0.5099\n",
      "Epoch 61/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.5209 - acc: 0.8117 - val_loss: 2.1343 - val_acc: 0.5122\n",
      "Epoch 62/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.5222 - acc: 0.8129 - val_loss: 2.1691 - val_acc: 0.5140\n",
      "Epoch 63/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.4992 - acc: 0.8212 - val_loss: 2.1547 - val_acc: 0.5079\n",
      "Epoch 64/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.5134 - acc: 0.8152 - val_loss: 2.2141 - val_acc: 0.5081\n",
      "Epoch 65/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.4941 - acc: 0.8216 - val_loss: 2.2755 - val_acc: 0.5042\n",
      "Epoch 66/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4861 - acc: 0.8261 - val_loss: 2.2957 - val_acc: 0.5045\n",
      "Epoch 67/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.4635 - acc: 0.8333 - val_loss: 2.3209 - val_acc: 0.4955\n",
      "Epoch 68/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.4698 - acc: 0.8306 - val_loss: 2.3117 - val_acc: 0.5058\n",
      "Epoch 69/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.4671 - acc: 0.8324 - val_loss: 2.3192 - val_acc: 0.5037\n",
      "Epoch 70/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.4616 - acc: 0.8332 - val_loss: 2.3252 - val_acc: 0.5105\n",
      "Epoch 71/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.4561 - acc: 0.8376 - val_loss: 2.3804 - val_acc: 0.5033\n",
      "Epoch 72/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.4254 - acc: 0.8486 - val_loss: 2.5551 - val_acc: 0.4960\n",
      "Epoch 73/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4442 - acc: 0.8401 - val_loss: 2.4296 - val_acc: 0.5089\n",
      "Epoch 74/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.4279 - acc: 0.8451 - val_loss: 2.4688 - val_acc: 0.5099\n",
      "Epoch 75/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4123 - acc: 0.8504 - val_loss: 2.5261 - val_acc: 0.5077\n",
      "Epoch 76/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4161 - acc: 0.8516 - val_loss: 2.4928 - val_acc: 0.4986\n",
      "Epoch 77/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.4097 - acc: 0.8534 - val_loss: 2.5468 - val_acc: 0.5088\n",
      "Epoch 78/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.4053 - acc: 0.8540 - val_loss: 2.5357 - val_acc: 0.5085\n",
      "Epoch 79/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.4078 - acc: 0.8518 - val_loss: 2.6488 - val_acc: 0.5071\n",
      "Epoch 80/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.3768 - acc: 0.8646 - val_loss: 2.6055 - val_acc: 0.4956\n",
      "Epoch 81/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.3778 - acc: 0.8642 - val_loss: 2.6645 - val_acc: 0.5133\n",
      "Epoch 82/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.3875 - acc: 0.8603 - val_loss: 2.6587 - val_acc: 0.5046\n",
      "Epoch 83/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.3585 - acc: 0.8698 - val_loss: 2.7480 - val_acc: 0.5056\n",
      "Epoch 84/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.3563 - acc: 0.8714 - val_loss: 2.7405 - val_acc: 0.4994\n",
      "Epoch 85/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.3746 - acc: 0.8642 - val_loss: 2.7520 - val_acc: 0.5036\n",
      "Epoch 86/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.3713 - acc: 0.8670 - val_loss: 2.7818 - val_acc: 0.4989\n",
      "Epoch 87/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.3811 - acc: 0.8623 - val_loss: 2.8956 - val_acc: 0.5021\n",
      "Epoch 88/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.3506 - acc: 0.8753 - val_loss: 2.7705 - val_acc: 0.4965\n",
      "Epoch 89/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.3420 - acc: 0.8776 - val_loss: 2.8594 - val_acc: 0.5041\n",
      "Epoch 90/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.3226 - acc: 0.8843 - val_loss: 2.8863 - val_acc: 0.5038\n",
      "Epoch 91/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.3582 - acc: 0.8711 - val_loss: 2.9014 - val_acc: 0.4947\n",
      "Epoch 92/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.3403 - acc: 0.8776 - val_loss: 2.8637 - val_acc: 0.4982\n",
      "Epoch 93/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.3154 - acc: 0.8873 - val_loss: 2.8790 - val_acc: 0.5001\n",
      "Epoch 94/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.3176 - acc: 0.8868 - val_loss: 3.0029 - val_acc: 0.4977\n",
      "Epoch 95/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.3450 - acc: 0.8756 - val_loss: 3.0202 - val_acc: 0.4968\n",
      "Epoch 96/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.3392 - acc: 0.8762 - val_loss: 3.0148 - val_acc: 0.5010\n",
      "Epoch 97/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.3063 - acc: 0.8899 - val_loss: 2.9913 - val_acc: 0.5029\n",
      "Epoch 98/500\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.2943 - acc: 0.8945 - val_loss: 3.0177 - val_acc: 0.4979\n",
      "Epoch 99/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.3057 - acc: 0.8912 - val_loss: 3.1360 - val_acc: 0.5008\n",
      "Epoch 100/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.3309 - acc: 0.8803 - val_loss: 3.0862 - val_acc: 0.5001\n",
      "Epoch 101/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.3001 - acc: 0.8920 - val_loss: 3.0707 - val_acc: 0.4993\n",
      "Epoch 102/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.3013 - acc: 0.8913 - val_loss: 3.1666 - val_acc: 0.4960\n",
      "Epoch 103/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2858 - acc: 0.8970 - val_loss: 3.1474 - val_acc: 0.4938\n",
      "Epoch 104/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.3016 - acc: 0.8932 - val_loss: 3.1620 - val_acc: 0.5008\n",
      "Epoch 105/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.3134 - acc: 0.8890 - val_loss: 3.2016 - val_acc: 0.4918\n",
      "Epoch 106/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.3237 - acc: 0.8843 - val_loss: 3.1993 - val_acc: 0.4943\n",
      "Epoch 107/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2793 - acc: 0.8994 - val_loss: 3.1713 - val_acc: 0.5076\n",
      "Epoch 108/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2712 - acc: 0.9023 - val_loss: 3.2141 - val_acc: 0.4955\n",
      "Epoch 109/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2752 - acc: 0.9009 - val_loss: 3.3193 - val_acc: 0.4970\n",
      "Epoch 110/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2724 - acc: 0.9023 - val_loss: 3.3190 - val_acc: 0.5040\n",
      "Epoch 111/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2748 - acc: 0.9022 - val_loss: 3.2757 - val_acc: 0.4979\n",
      "Epoch 112/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.3122 - acc: 0.8879 - val_loss: 3.2167 - val_acc: 0.5004\n",
      "Epoch 113/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.2802 - acc: 0.8987 - val_loss: 3.4026 - val_acc: 0.4907\n",
      "Epoch 114/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2641 - acc: 0.9053 - val_loss: 3.4276 - val_acc: 0.4896\n",
      "Epoch 115/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2607 - acc: 0.9046 - val_loss: 3.3373 - val_acc: 0.5001\n",
      "Epoch 116/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2533 - acc: 0.9083 - val_loss: 3.4106 - val_acc: 0.4926\n",
      "Epoch 117/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2351 - acc: 0.9149 - val_loss: 3.4372 - val_acc: 0.4970\n",
      "Epoch 118/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2564 - acc: 0.9077 - val_loss: 3.4381 - val_acc: 0.4882\n",
      "Epoch 119/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2899 - acc: 0.8961 - val_loss: 3.4138 - val_acc: 0.4905\n",
      "Epoch 120/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2618 - acc: 0.9052 - val_loss: 3.4556 - val_acc: 0.4866\n",
      "Epoch 121/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2861 - acc: 0.8983 - val_loss: 3.3751 - val_acc: 0.4948\n",
      "Epoch 122/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2301 - acc: 0.9184 - val_loss: 3.5173 - val_acc: 0.4947\n",
      "Epoch 123/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2221 - acc: 0.9221 - val_loss: 3.4642 - val_acc: 0.4939\n",
      "Epoch 124/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2527 - acc: 0.9102 - val_loss: 3.5410 - val_acc: 0.5002\n",
      "Epoch 125/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2356 - acc: 0.9162 - val_loss: 3.5815 - val_acc: 0.5004\n",
      "Epoch 126/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2712 - acc: 0.9047 - val_loss: 3.4742 - val_acc: 0.4916\n",
      "Epoch 127/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2587 - acc: 0.9086 - val_loss: 3.4664 - val_acc: 0.4948\n",
      "Epoch 128/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2413 - acc: 0.9140 - val_loss: 3.6502 - val_acc: 0.4937\n",
      "Epoch 129/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2286 - acc: 0.9189 - val_loss: 3.6422 - val_acc: 0.4982\n",
      "Epoch 130/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2345 - acc: 0.9155 - val_loss: 3.6704 - val_acc: 0.4872\n",
      "Epoch 131/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2430 - acc: 0.9126 - val_loss: 3.5869 - val_acc: 0.4925\n",
      "Epoch 132/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1947 - acc: 0.9313 - val_loss: 3.7133 - val_acc: 0.4858\n",
      "Epoch 133/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2303 - acc: 0.9176 - val_loss: 3.5537 - val_acc: 0.4923\n",
      "Epoch 134/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2465 - acc: 0.9139 - val_loss: 3.6792 - val_acc: 0.4852\n",
      "Epoch 135/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2211 - acc: 0.9211 - val_loss: 3.6548 - val_acc: 0.4968\n",
      "Epoch 136/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2279 - acc: 0.9188 - val_loss: 3.7402 - val_acc: 0.4943\n",
      "Epoch 137/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2353 - acc: 0.9156 - val_loss: 3.6537 - val_acc: 0.4934\n",
      "Epoch 138/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2382 - acc: 0.9148 - val_loss: 3.6785 - val_acc: 0.4925\n",
      "Epoch 139/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2010 - acc: 0.9281 - val_loss: 3.7842 - val_acc: 0.4923\n",
      "Epoch 140/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2251 - acc: 0.9198 - val_loss: 3.7000 - val_acc: 0.5003\n",
      "Epoch 141/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2430 - acc: 0.9159 - val_loss: 3.6887 - val_acc: 0.4908\n",
      "Epoch 142/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2391 - acc: 0.9155 - val_loss: 3.7388 - val_acc: 0.4959\n",
      "Epoch 143/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2148 - acc: 0.9228 - val_loss: 3.8402 - val_acc: 0.4930\n",
      "Epoch 144/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.1879 - acc: 0.9331 - val_loss: 3.8814 - val_acc: 0.4897\n",
      "Epoch 145/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2015 - acc: 0.9278 - val_loss: 3.7768 - val_acc: 0.4875\n",
      "Epoch 146/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2164 - acc: 0.9241 - val_loss: 3.7990 - val_acc: 0.4933\n",
      "Epoch 147/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2319 - acc: 0.9192 - val_loss: 3.8210 - val_acc: 0.4910\n",
      "Epoch 148/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.1867 - acc: 0.9334 - val_loss: 3.9203 - val_acc: 0.4921\n",
      "Epoch 149/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2194 - acc: 0.9239 - val_loss: 3.8686 - val_acc: 0.4934\n",
      "Epoch 150/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1890 - acc: 0.9328 - val_loss: 3.8971 - val_acc: 0.4829\n",
      "Epoch 151/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2354 - acc: 0.9164 - val_loss: 3.8317 - val_acc: 0.4885\n",
      "Epoch 152/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2599 - acc: 0.9086 - val_loss: 3.8072 - val_acc: 0.4913\n",
      "Epoch 153/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1908 - acc: 0.9322 - val_loss: 3.8470 - val_acc: 0.4937\n",
      "Epoch 154/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1868 - acc: 0.9337 - val_loss: 3.9719 - val_acc: 0.4885\n",
      "Epoch 155/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1990 - acc: 0.9298 - val_loss: 3.8730 - val_acc: 0.4938\n",
      "Epoch 156/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1935 - acc: 0.9300 - val_loss: 3.9528 - val_acc: 0.4999\n",
      "Epoch 157/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.2283 - acc: 0.9208 - val_loss: 3.8309 - val_acc: 0.4949\n",
      "Epoch 158/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1701 - acc: 0.9398 - val_loss: 3.9951 - val_acc: 0.4938\n",
      "Epoch 159/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1733 - acc: 0.9377 - val_loss: 4.0435 - val_acc: 0.4860\n",
      "Epoch 160/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2062 - acc: 0.9273 - val_loss: 3.9680 - val_acc: 0.4962\n",
      "Epoch 161/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.2029 - acc: 0.9300 - val_loss: 3.9352 - val_acc: 0.4867\n",
      "Epoch 162/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.2166 - acc: 0.9245 - val_loss: 3.9257 - val_acc: 0.4942\n",
      "Epoch 163/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1731 - acc: 0.9382 - val_loss: 4.0265 - val_acc: 0.4897\n",
      "Epoch 164/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.1525 - acc: 0.9454 - val_loss: 4.0753 - val_acc: 0.4933\n",
      "Epoch 165/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2230 - acc: 0.9211 - val_loss: 4.0764 - val_acc: 0.4893\n",
      "Epoch 166/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2023 - acc: 0.9292 - val_loss: 4.0809 - val_acc: 0.4809\n",
      "Epoch 167/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2199 - acc: 0.9243 - val_loss: 3.9777 - val_acc: 0.4954\n",
      "Epoch 168/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1468 - acc: 0.9482 - val_loss: 4.1136 - val_acc: 0.4851\n",
      "Epoch 169/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1746 - acc: 0.9393 - val_loss: 4.0445 - val_acc: 0.4897\n",
      "Epoch 170/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1729 - acc: 0.9388 - val_loss: 4.1093 - val_acc: 0.4899\n",
      "Epoch 171/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1660 - acc: 0.9409 - val_loss: 4.1117 - val_acc: 0.4948\n",
      "Epoch 172/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1811 - acc: 0.9359 - val_loss: 4.0827 - val_acc: 0.4895\n",
      "Epoch 173/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2145 - acc: 0.9260 - val_loss: 4.0771 - val_acc: 0.4829\n",
      "Epoch 174/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2509 - acc: 0.9131 - val_loss: 4.0006 - val_acc: 0.4827\n",
      "Epoch 175/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1683 - acc: 0.9404 - val_loss: 4.0741 - val_acc: 0.4961\n",
      "Epoch 176/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1645 - acc: 0.9408 - val_loss: 4.0627 - val_acc: 0.4907\n",
      "Epoch 177/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1248 - acc: 0.9569 - val_loss: 4.0852 - val_acc: 0.4930\n",
      "Epoch 178/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1660 - acc: 0.9418 - val_loss: 4.1646 - val_acc: 0.4900\n",
      "Epoch 179/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1985 - acc: 0.9312 - val_loss: 4.1358 - val_acc: 0.4951\n",
      "Epoch 180/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1507 - acc: 0.9469 - val_loss: 4.1521 - val_acc: 0.4940\n",
      "Epoch 181/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2093 - acc: 0.9274 - val_loss: 4.0753 - val_acc: 0.4941\n",
      "Epoch 182/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2017 - acc: 0.9290 - val_loss: 4.1608 - val_acc: 0.4817\n",
      "Epoch 183/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1766 - acc: 0.9379 - val_loss: 4.1110 - val_acc: 0.4946\n",
      "Epoch 184/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2044 - acc: 0.9285 - val_loss: 4.1468 - val_acc: 0.4858\n",
      "Epoch 185/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1650 - acc: 0.9434 - val_loss: 4.1996 - val_acc: 0.4928\n",
      "Epoch 186/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1582 - acc: 0.9447 - val_loss: 4.2278 - val_acc: 0.4883\n",
      "Epoch 187/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1255 - acc: 0.9557 - val_loss: 4.3029 - val_acc: 0.4894\n",
      "Epoch 188/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1551 - acc: 0.9460 - val_loss: 4.2083 - val_acc: 0.4865\n",
      "Epoch 189/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.2189 - acc: 0.9244 - val_loss: 4.2578 - val_acc: 0.4816\n",
      "Epoch 190/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.2057 - acc: 0.9293 - val_loss: 4.0764 - val_acc: 0.4990\n",
      "Epoch 191/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1624 - acc: 0.9431 - val_loss: 4.1554 - val_acc: 0.4861\n",
      "Epoch 192/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1777 - acc: 0.9388 - val_loss: 4.1331 - val_acc: 0.4950\n",
      "Epoch 193/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1383 - acc: 0.9500 - val_loss: 4.1466 - val_acc: 0.4980\n",
      "Epoch 194/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1575 - acc: 0.9446 - val_loss: 4.1893 - val_acc: 0.4940\n",
      "Epoch 195/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1839 - acc: 0.9369 - val_loss: 4.2869 - val_acc: 0.4855\n",
      "Epoch 196/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1433 - acc: 0.9503 - val_loss: 4.2622 - val_acc: 0.4918\n",
      "Epoch 197/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1415 - acc: 0.9498 - val_loss: 4.3456 - val_acc: 0.4828\n",
      "Epoch 198/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1736 - acc: 0.9399 - val_loss: 4.1962 - val_acc: 0.4931\n",
      "Epoch 199/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.1834 - acc: 0.9358 - val_loss: 4.3565 - val_acc: 0.4892\n",
      "Epoch 200/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.1916 - acc: 0.9331 - val_loss: 4.2838 - val_acc: 0.4891\n",
      "Epoch 201/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1269 - acc: 0.9554 - val_loss: 4.2186 - val_acc: 0.4952\n",
      "Epoch 202/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1020 - acc: 0.9651 - val_loss: 4.3321 - val_acc: 0.4943\n",
      "Epoch 203/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1151 - acc: 0.9595 - val_loss: 4.4777 - val_acc: 0.4793\n",
      "Epoch 204/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2329 - acc: 0.9220 - val_loss: 4.2997 - val_acc: 0.4895\n",
      "Epoch 205/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1911 - acc: 0.9342 - val_loss: 4.2926 - val_acc: 0.4908\n",
      "Epoch 206/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1547 - acc: 0.9459 - val_loss: 4.2884 - val_acc: 0.4843\n",
      "Epoch 207/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1459 - acc: 0.9484 - val_loss: 4.2825 - val_acc: 0.4955\n",
      "Epoch 208/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1361 - acc: 0.9522 - val_loss: 4.3217 - val_acc: 0.4919\n",
      "Epoch 209/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1733 - acc: 0.9393 - val_loss: 4.4066 - val_acc: 0.4875\n",
      "Epoch 210/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1508 - acc: 0.9479 - val_loss: 4.3931 - val_acc: 0.4883\n",
      "Epoch 211/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1861 - acc: 0.9360 - val_loss: 4.3335 - val_acc: 0.4832\n",
      "Epoch 212/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1132 - acc: 0.9607 - val_loss: 4.3591 - val_acc: 0.4887\n",
      "Epoch 213/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1161 - acc: 0.9600 - val_loss: 4.2993 - val_acc: 0.5022\n",
      "Epoch 214/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1572 - acc: 0.9448 - val_loss: 4.3859 - val_acc: 0.4904\n",
      "Epoch 215/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2034 - acc: 0.9315 - val_loss: 4.2950 - val_acc: 0.4862\n",
      "Epoch 216/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.2258 - acc: 0.9247 - val_loss: 4.2394 - val_acc: 0.4944\n",
      "Epoch 217/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0882 - acc: 0.9705 - val_loss: 4.3973 - val_acc: 0.4939\n",
      "Epoch 218/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0694 - acc: 0.9762 - val_loss: 4.3530 - val_acc: 0.4996\n",
      "Epoch 219/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0975 - acc: 0.9665 - val_loss: 4.4603 - val_acc: 0.4990\n",
      "Epoch 220/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2996 - acc: 0.9047 - val_loss: 4.2700 - val_acc: 0.4843\n",
      "Epoch 221/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1411 - acc: 0.9515 - val_loss: 4.3473 - val_acc: 0.4947\n",
      "Epoch 222/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1416 - acc: 0.9515 - val_loss: 4.3708 - val_acc: 0.4909\n",
      "Epoch 223/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1344 - acc: 0.9532 - val_loss: 4.4424 - val_acc: 0.4891\n",
      "Epoch 224/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1447 - acc: 0.9496 - val_loss: 4.4065 - val_acc: 0.4862\n",
      "Epoch 225/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1336 - acc: 0.9535 - val_loss: 4.4134 - val_acc: 0.4927\n",
      "Epoch 226/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1354 - acc: 0.9531 - val_loss: 4.4482 - val_acc: 0.4862\n",
      "Epoch 227/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1082 - acc: 0.9628 - val_loss: 4.4344 - val_acc: 0.4934\n",
      "Epoch 228/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1464 - acc: 0.9485 - val_loss: 4.5512 - val_acc: 0.4797\n",
      "Epoch 229/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1252 - acc: 0.9561 - val_loss: 4.5003 - val_acc: 0.4956\n",
      "Epoch 230/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1518 - acc: 0.9469 - val_loss: 4.4083 - val_acc: 0.4866\n",
      "Epoch 231/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1921 - acc: 0.9357 - val_loss: 4.4015 - val_acc: 0.4894\n",
      "Epoch 232/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1592 - acc: 0.9460 - val_loss: 4.4179 - val_acc: 0.4938\n",
      "Epoch 233/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1362 - acc: 0.9527 - val_loss: 4.4672 - val_acc: 0.4929\n",
      "Epoch 234/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1491 - acc: 0.9504 - val_loss: 4.4931 - val_acc: 0.4856\n",
      "Epoch 235/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1302 - acc: 0.9555 - val_loss: 4.5656 - val_acc: 0.4883\n",
      "Epoch 236/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1297 - acc: 0.9551 - val_loss: 4.5054 - val_acc: 0.4911\n",
      "Epoch 237/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0969 - acc: 0.9665 - val_loss: 4.5067 - val_acc: 0.4908\n",
      "Epoch 238/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1180 - acc: 0.9596 - val_loss: 4.5428 - val_acc: 0.4871\n",
      "Epoch 239/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.2338 - acc: 0.9249 - val_loss: 4.3745 - val_acc: 0.4866\n",
      "Epoch 240/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1578 - acc: 0.9462 - val_loss: 4.5107 - val_acc: 0.4904\n",
      "Epoch 241/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0823 - acc: 0.9708 - val_loss: 4.4134 - val_acc: 0.4916\n",
      "Epoch 242/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0931 - acc: 0.9679 - val_loss: 4.6197 - val_acc: 0.4863\n",
      "Epoch 243/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1457 - acc: 0.9513 - val_loss: 4.4096 - val_acc: 0.4909\n",
      "Epoch 244/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1825 - acc: 0.9383 - val_loss: 4.4568 - val_acc: 0.4954\n",
      "Epoch 245/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1331 - acc: 0.9538 - val_loss: 4.4619 - val_acc: 0.4941\n",
      "Epoch 246/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1444 - acc: 0.9499 - val_loss: 4.3908 - val_acc: 0.4935\n",
      "Epoch 247/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1188 - acc: 0.9585 - val_loss: 4.4849 - val_acc: 0.4975\n",
      "Epoch 248/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1002 - acc: 0.9642 - val_loss: 4.5001 - val_acc: 0.4883\n",
      "Epoch 249/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1198 - acc: 0.9586 - val_loss: 4.4594 - val_acc: 0.4887\n",
      "Epoch 250/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.2013 - acc: 0.9339 - val_loss: 4.5162 - val_acc: 0.4863\n",
      "Epoch 251/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1318 - acc: 0.9540 - val_loss: 4.5534 - val_acc: 0.4973\n",
      "Epoch 252/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1152 - acc: 0.9599 - val_loss: 4.6427 - val_acc: 0.4875\n",
      "Epoch 253/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1341 - acc: 0.9541 - val_loss: 4.4636 - val_acc: 0.4930\n",
      "Epoch 254/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1738 - acc: 0.9425 - val_loss: 4.4578 - val_acc: 0.4964\n",
      "Epoch 255/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0981 - acc: 0.9660 - val_loss: 4.5296 - val_acc: 0.4934\n",
      "Epoch 256/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1176 - acc: 0.9588 - val_loss: 4.5848 - val_acc: 0.4924\n",
      "Epoch 257/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1004 - acc: 0.9659 - val_loss: 4.5684 - val_acc: 0.4953\n",
      "Epoch 258/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1237 - acc: 0.9577 - val_loss: 4.5839 - val_acc: 0.4918\n",
      "Epoch 259/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1788 - acc: 0.9417 - val_loss: 4.5609 - val_acc: 0.4882\n",
      "Epoch 260/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1431 - acc: 0.9519 - val_loss: 4.4516 - val_acc: 0.4947\n",
      "Epoch 261/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0986 - acc: 0.9664 - val_loss: 4.5481 - val_acc: 0.4918\n",
      "Epoch 262/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0984 - acc: 0.9665 - val_loss: 4.5519 - val_acc: 0.4987\n",
      "Epoch 263/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1099 - acc: 0.9627 - val_loss: 4.6070 - val_acc: 0.4979\n",
      "Epoch 264/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1925 - acc: 0.9361 - val_loss: 4.5155 - val_acc: 0.4797\n",
      "Epoch 265/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1504 - acc: 0.9486 - val_loss: 4.5585 - val_acc: 0.4927\n",
      "Epoch 266/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1112 - acc: 0.9614 - val_loss: 4.6311 - val_acc: 0.4966\n",
      "Epoch 267/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0903 - acc: 0.9699 - val_loss: 4.6718 - val_acc: 0.4897\n",
      "Epoch 268/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1294 - acc: 0.9562 - val_loss: 4.5895 - val_acc: 0.4950\n",
      "Epoch 269/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1199 - acc: 0.9592 - val_loss: 4.6801 - val_acc: 0.4927\n",
      "Epoch 270/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1522 - acc: 0.9487 - val_loss: 4.6748 - val_acc: 0.4920\n",
      "Epoch 271/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1083 - acc: 0.9626 - val_loss: 4.6729 - val_acc: 0.4903\n",
      "Epoch 272/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0856 - acc: 0.9704 - val_loss: 4.7228 - val_acc: 0.4937\n",
      "Epoch 273/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1407 - acc: 0.9534 - val_loss: 4.7436 - val_acc: 0.4931\n",
      "Epoch 274/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1607 - acc: 0.9463 - val_loss: 4.5068 - val_acc: 0.4904\n",
      "Epoch 275/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1569 - acc: 0.9484 - val_loss: 4.5409 - val_acc: 0.4857\n",
      "Epoch 276/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1218 - acc: 0.9582 - val_loss: 4.5968 - val_acc: 0.4914\n",
      "Epoch 277/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1177 - acc: 0.9596 - val_loss: 4.6165 - val_acc: 0.4950\n",
      "Epoch 278/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0606 - acc: 0.9794 - val_loss: 4.7195 - val_acc: 0.4914\n",
      "Epoch 279/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0758 - acc: 0.9733 - val_loss: 4.7250 - val_acc: 0.4845\n",
      "Epoch 280/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1161 - acc: 0.9606 - val_loss: 4.6600 - val_acc: 0.4896\n",
      "Epoch 281/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.2001 - acc: 0.9369 - val_loss: 4.5513 - val_acc: 0.4852\n",
      "Epoch 282/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1254 - acc: 0.9575 - val_loss: 4.6107 - val_acc: 0.4913\n",
      "Epoch 283/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.0972 - acc: 0.9665 - val_loss: 4.6703 - val_acc: 0.4960\n",
      "Epoch 284/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.1072 - acc: 0.9619 - val_loss: 4.6996 - val_acc: 0.4849\n",
      "Epoch 285/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1102 - acc: 0.9621 - val_loss: 4.7618 - val_acc: 0.4787\n",
      "Epoch 286/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1252 - acc: 0.9577 - val_loss: 4.6171 - val_acc: 0.4979\n",
      "Epoch 287/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1097 - acc: 0.9623 - val_loss: 4.7159 - val_acc: 0.4880\n",
      "Epoch 288/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1532 - acc: 0.9490 - val_loss: 4.7586 - val_acc: 0.4827\n",
      "Epoch 289/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1292 - acc: 0.9553 - val_loss: 4.7038 - val_acc: 0.4906\n",
      "Epoch 290/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0938 - acc: 0.9681 - val_loss: 4.7099 - val_acc: 0.4965\n",
      "Epoch 291/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0667 - acc: 0.9770 - val_loss: 4.7370 - val_acc: 0.4985\n",
      "Epoch 292/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0555 - acc: 0.9808 - val_loss: 4.7780 - val_acc: 0.4914\n",
      "Epoch 293/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1999 - acc: 0.9373 - val_loss: 4.6342 - val_acc: 0.4854\n",
      "Epoch 294/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1838 - acc: 0.9413 - val_loss: 4.6008 - val_acc: 0.4866\n",
      "Epoch 295/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0723 - acc: 0.9762 - val_loss: 4.5842 - val_acc: 0.4969\n",
      "Epoch 296/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0718 - acc: 0.9750 - val_loss: 4.7119 - val_acc: 0.4926\n",
      "Epoch 297/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0766 - acc: 0.9747 - val_loss: 4.7727 - val_acc: 0.4914\n",
      "Epoch 298/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1765 - acc: 0.9420 - val_loss: 4.7133 - val_acc: 0.4853\n",
      "Epoch 299/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1675 - acc: 0.9447 - val_loss: 4.6283 - val_acc: 0.4852\n",
      "Epoch 300/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0785 - acc: 0.9734 - val_loss: 4.7146 - val_acc: 0.4938\n",
      "Epoch 301/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0625 - acc: 0.9789 - val_loss: 4.7334 - val_acc: 0.4911\n",
      "Epoch 302/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0815 - acc: 0.9722 - val_loss: 4.7435 - val_acc: 0.4904\n",
      "Epoch 303/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1600 - acc: 0.9479 - val_loss: 4.7227 - val_acc: 0.4880\n",
      "Epoch 304/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1361 - acc: 0.9549 - val_loss: 4.6822 - val_acc: 0.4874\n",
      "Epoch 305/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1110 - acc: 0.9629 - val_loss: 4.7032 - val_acc: 0.4969\n",
      "Epoch 306/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0596 - acc: 0.9798 - val_loss: 4.7962 - val_acc: 0.4968\n",
      "Epoch 307/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0850 - acc: 0.9711 - val_loss: 4.9692 - val_acc: 0.4847\n",
      "Epoch 308/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1167 - acc: 0.9602 - val_loss: 4.7455 - val_acc: 0.4921\n",
      "Epoch 309/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0918 - acc: 0.9686 - val_loss: 4.8493 - val_acc: 0.4860\n",
      "Epoch 310/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.2073 - acc: 0.9330 - val_loss: 4.6986 - val_acc: 0.4875\n",
      "Epoch 311/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1006 - acc: 0.9667 - val_loss: 4.7381 - val_acc: 0.4925\n",
      "Epoch 312/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0670 - acc: 0.9778 - val_loss: 4.7713 - val_acc: 0.4942\n",
      "Epoch 313/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0836 - acc: 0.9709 - val_loss: 4.8101 - val_acc: 0.4897\n",
      "Epoch 314/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1376 - acc: 0.9556 - val_loss: 4.6760 - val_acc: 0.4941\n",
      "Epoch 315/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1766 - acc: 0.9422 - val_loss: 4.6596 - val_acc: 0.4886\n",
      "Epoch 316/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0750 - acc: 0.9745 - val_loss: 4.7432 - val_acc: 0.4952\n",
      "Epoch 317/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1015 - acc: 0.9654 - val_loss: 4.7363 - val_acc: 0.4949\n",
      "Epoch 318/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0723 - acc: 0.9759 - val_loss: 4.7325 - val_acc: 0.4960\n",
      "Epoch 319/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0725 - acc: 0.9753 - val_loss: 4.8430 - val_acc: 0.4935\n",
      "Epoch 320/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1401 - acc: 0.9543 - val_loss: 4.7335 - val_acc: 0.4936\n",
      "Epoch 321/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1524 - acc: 0.9493 - val_loss: 4.7674 - val_acc: 0.4936\n",
      "Epoch 322/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1227 - acc: 0.9594 - val_loss: 4.6730 - val_acc: 0.4960\n",
      "Epoch 323/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0576 - acc: 0.9800 - val_loss: 4.7582 - val_acc: 0.4944\n",
      "Epoch 324/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0499 - acc: 0.9835 - val_loss: 4.8065 - val_acc: 0.4975\n",
      "Epoch 325/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1203 - acc: 0.9587 - val_loss: 4.7837 - val_acc: 0.4893\n",
      "Epoch 326/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1049 - acc: 0.9640 - val_loss: 4.7483 - val_acc: 0.4934\n",
      "Epoch 327/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1102 - acc: 0.9629 - val_loss: 4.8261 - val_acc: 0.4892\n",
      "Epoch 328/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1640 - acc: 0.9483 - val_loss: 4.8072 - val_acc: 0.4931\n",
      "Epoch 329/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1250 - acc: 0.9580 - val_loss: 4.8443 - val_acc: 0.4878\n",
      "Epoch 330/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0923 - acc: 0.9692 - val_loss: 4.8212 - val_acc: 0.4942\n",
      "Epoch 331/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0880 - acc: 0.9694 - val_loss: 4.7905 - val_acc: 0.4932\n",
      "Epoch 332/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0852 - acc: 0.9706 - val_loss: 4.7492 - val_acc: 0.4950\n",
      "Epoch 333/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1306 - acc: 0.9576 - val_loss: 4.7975 - val_acc: 0.4906\n",
      "Epoch 334/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.1396 - acc: 0.9544 - val_loss: 4.7878 - val_acc: 0.4889\n",
      "Epoch 335/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0686 - acc: 0.9776 - val_loss: 4.7129 - val_acc: 0.5000\n",
      "Epoch 336/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0263 - acc: 0.9924 - val_loss: 4.8001 - val_acc: 0.5027\n",
      "Epoch 337/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0585 - acc: 0.9808 - val_loss: 4.8606 - val_acc: 0.4868\n",
      "Epoch 338/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1915 - acc: 0.9392 - val_loss: 4.7916 - val_acc: 0.4928\n",
      "Epoch 339/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1773 - acc: 0.9427 - val_loss: 4.7960 - val_acc: 0.4888\n",
      "Epoch 340/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0746 - acc: 0.9750 - val_loss: 4.8134 - val_acc: 0.4925\n",
      "Epoch 341/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0391 - acc: 0.9872 - val_loss: 4.8214 - val_acc: 0.4935\n",
      "Epoch 342/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1051 - acc: 0.9650 - val_loss: 4.9107 - val_acc: 0.4847\n",
      "Epoch 343/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1724 - acc: 0.9454 - val_loss: 4.9449 - val_acc: 0.4759\n",
      "Epoch 344/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1066 - acc: 0.9643 - val_loss: 4.7763 - val_acc: 0.4903\n",
      "Epoch 345/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0496 - acc: 0.9837 - val_loss: 4.8456 - val_acc: 0.4962\n",
      "Epoch 346/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0533 - acc: 0.9820 - val_loss: 4.9172 - val_acc: 0.4931\n",
      "Epoch 347/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0978 - acc: 0.9671 - val_loss: 4.9169 - val_acc: 0.4930\n",
      "Epoch 348/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1642 - acc: 0.9469 - val_loss: 4.7581 - val_acc: 0.4847\n",
      "Epoch 349/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1104 - acc: 0.9629 - val_loss: 4.7667 - val_acc: 0.4914\n",
      "Epoch 350/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0705 - acc: 0.9762 - val_loss: 4.8836 - val_acc: 0.4933\n",
      "Epoch 351/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0578 - acc: 0.9802 - val_loss: 4.9100 - val_acc: 0.4903\n",
      "Epoch 352/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1377 - acc: 0.9550 - val_loss: 4.8587 - val_acc: 0.4941\n",
      "Epoch 353/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1223 - acc: 0.9604 - val_loss: 4.7709 - val_acc: 0.4966\n",
      "Epoch 354/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0503 - acc: 0.9832 - val_loss: 4.8668 - val_acc: 0.4987\n",
      "Epoch 355/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0399 - acc: 0.9867 - val_loss: 4.9496 - val_acc: 0.4981\n",
      "Epoch 356/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1523 - acc: 0.9527 - val_loss: 4.8036 - val_acc: 0.4870\n",
      "Epoch 357/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1684 - acc: 0.9464 - val_loss: 4.8274 - val_acc: 0.4925\n",
      "Epoch 358/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1201 - acc: 0.9609 - val_loss: 4.7845 - val_acc: 0.4919\n",
      "Epoch 359/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0583 - acc: 0.9814 - val_loss: 4.8717 - val_acc: 0.4901\n",
      "Epoch 360/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0832 - acc: 0.9717 - val_loss: 4.8736 - val_acc: 0.4946\n",
      "Epoch 361/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0404 - acc: 0.9869 - val_loss: 4.9620 - val_acc: 0.4924\n",
      "Epoch 362/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1013 - acc: 0.9664 - val_loss: 4.8452 - val_acc: 0.4850\n",
      "Epoch 363/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1375 - acc: 0.9550 - val_loss: 5.0034 - val_acc: 0.4892\n",
      "Epoch 364/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1442 - acc: 0.9551 - val_loss: 4.8883 - val_acc: 0.4867\n",
      "Epoch 365/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1017 - acc: 0.9658 - val_loss: 4.8929 - val_acc: 0.4849\n",
      "Epoch 366/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0648 - acc: 0.9789 - val_loss: 4.8662 - val_acc: 0.4990\n",
      "Epoch 367/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0716 - acc: 0.9754 - val_loss: 4.9635 - val_acc: 0.4921\n",
      "Epoch 368/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1287 - acc: 0.9582 - val_loss: 4.8484 - val_acc: 0.4808\n",
      "Epoch 369/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0931 - acc: 0.9687 - val_loss: 4.9448 - val_acc: 0.4919\n",
      "Epoch 370/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1435 - acc: 0.9534 - val_loss: 4.8659 - val_acc: 0.4881\n",
      "Epoch 371/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0740 - acc: 0.9748 - val_loss: 4.8846 - val_acc: 0.4927\n",
      "Epoch 372/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0354 - acc: 0.9888 - val_loss: 4.9144 - val_acc: 0.4949\n",
      "Epoch 373/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0476 - acc: 0.9838 - val_loss: 4.9800 - val_acc: 0.4931\n",
      "Epoch 374/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1102 - acc: 0.9646 - val_loss: 4.9704 - val_acc: 0.4826\n",
      "Epoch 375/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2462 - acc: 0.9285 - val_loss: 4.6813 - val_acc: 0.4936\n",
      "Epoch 376/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0547 - acc: 0.9819 - val_loss: 4.8479 - val_acc: 0.5004\n",
      "Epoch 377/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0390 - acc: 0.9872 - val_loss: 4.9106 - val_acc: 0.4994\n",
      "Epoch 378/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0323 - acc: 0.9896 - val_loss: 4.9424 - val_acc: 0.4924\n",
      "Epoch 379/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1582 - acc: 0.9528 - val_loss: 4.8400 - val_acc: 0.4827\n",
      "Epoch 380/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1787 - acc: 0.9454 - val_loss: 4.7837 - val_acc: 0.4987\n",
      "Epoch 381/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0414 - acc: 0.9866 - val_loss: 4.8435 - val_acc: 0.4925\n",
      "Epoch 382/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0443 - acc: 0.9852 - val_loss: 4.8979 - val_acc: 0.4953\n",
      "Epoch 383/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0793 - acc: 0.9724 - val_loss: 4.9914 - val_acc: 0.4823\n",
      "Epoch 384/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1276 - acc: 0.9582 - val_loss: 4.8847 - val_acc: 0.4979\n",
      "Epoch 385/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1067 - acc: 0.9647 - val_loss: 4.9303 - val_acc: 0.4898\n",
      "Epoch 386/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0784 - acc: 0.9732 - val_loss: 4.8716 - val_acc: 0.4854\n",
      "Epoch 387/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1182 - acc: 0.9620 - val_loss: 4.9332 - val_acc: 0.4967\n",
      "Epoch 388/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1051 - acc: 0.9655 - val_loss: 4.8744 - val_acc: 0.4947\n",
      "Epoch 389/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0827 - acc: 0.9729 - val_loss: 4.9786 - val_acc: 0.4908\n",
      "Epoch 390/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0741 - acc: 0.9753 - val_loss: 4.9781 - val_acc: 0.4945\n",
      "Epoch 391/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0617 - acc: 0.9788 - val_loss: 4.9069 - val_acc: 0.4924\n",
      "Epoch 392/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0962 - acc: 0.9677 - val_loss: 4.9379 - val_acc: 0.4951\n",
      "Epoch 393/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1217 - acc: 0.9612 - val_loss: 5.0057 - val_acc: 0.4900\n",
      "Epoch 394/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1040 - acc: 0.9661 - val_loss: 4.9536 - val_acc: 0.4898\n",
      "Epoch 395/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0801 - acc: 0.9742 - val_loss: 4.9276 - val_acc: 0.4915\n",
      "Epoch 396/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0586 - acc: 0.9804 - val_loss: 4.9744 - val_acc: 0.4914\n",
      "Epoch 397/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0620 - acc: 0.9796 - val_loss: 4.9428 - val_acc: 0.4986\n",
      "Epoch 398/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0670 - acc: 0.9774 - val_loss: 5.0121 - val_acc: 0.4871\n",
      "Epoch 399/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1493 - acc: 0.9532 - val_loss: 4.9450 - val_acc: 0.4800\n",
      "Epoch 400/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1281 - acc: 0.9588 - val_loss: 4.9525 - val_acc: 0.4892\n",
      "Epoch 401/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0727 - acc: 0.9763 - val_loss: 4.9881 - val_acc: 0.4921\n",
      "Epoch 402/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0426 - acc: 0.9857 - val_loss: 5.0218 - val_acc: 0.4951\n",
      "Epoch 403/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0830 - acc: 0.9728 - val_loss: 5.0652 - val_acc: 0.4877\n",
      "Epoch 404/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.2125 - acc: 0.9364 - val_loss: 4.9183 - val_acc: 0.4894\n",
      "Epoch 405/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0640 - acc: 0.9786 - val_loss: 4.9315 - val_acc: 0.4937\n",
      "Epoch 406/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0561 - acc: 0.9811 - val_loss: 4.9507 - val_acc: 0.4932\n",
      "Epoch 407/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0735 - acc: 0.9769 - val_loss: 5.0357 - val_acc: 0.4955\n",
      "Epoch 408/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0870 - acc: 0.9701 - val_loss: 5.0542 - val_acc: 0.4948\n",
      "Epoch 409/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0678 - acc: 0.9772 - val_loss: 4.9932 - val_acc: 0.4896\n",
      "Epoch 410/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0783 - acc: 0.9739 - val_loss: 5.1249 - val_acc: 0.4833\n",
      "Epoch 411/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0903 - acc: 0.9708 - val_loss: 4.9557 - val_acc: 0.4872\n",
      "Epoch 412/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1209 - acc: 0.9614 - val_loss: 5.0103 - val_acc: 0.4890\n",
      "Epoch 413/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1332 - acc: 0.9568 - val_loss: 5.0605 - val_acc: 0.4943\n",
      "Epoch 414/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0937 - acc: 0.9699 - val_loss: 5.0205 - val_acc: 0.4897\n",
      "Epoch 415/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0491 - acc: 0.9837 - val_loss: 4.9706 - val_acc: 0.4968\n",
      "Epoch 416/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0433 - acc: 0.9858 - val_loss: 4.9908 - val_acc: 0.4951\n",
      "Epoch 417/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0927 - acc: 0.9699 - val_loss: 5.0320 - val_acc: 0.4923\n",
      "Epoch 418/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1370 - acc: 0.9554 - val_loss: 5.0870 - val_acc: 0.4847\n",
      "Epoch 419/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1364 - acc: 0.9574 - val_loss: 4.9620 - val_acc: 0.4878\n",
      "Epoch 420/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0632 - acc: 0.9790 - val_loss: 4.9981 - val_acc: 0.4945\n",
      "Epoch 421/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0430 - acc: 0.9862 - val_loss: 5.0173 - val_acc: 0.5005\n",
      "Epoch 422/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0625 - acc: 0.9793 - val_loss: 5.1610 - val_acc: 0.4877\n",
      "Epoch 423/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1117 - acc: 0.9636 - val_loss: 5.0591 - val_acc: 0.4886\n",
      "Epoch 424/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1512 - acc: 0.9524 - val_loss: 4.9284 - val_acc: 0.4940\n",
      "Epoch 425/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0532 - acc: 0.9814 - val_loss: 4.9656 - val_acc: 0.5008\n",
      "Epoch 426/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0788 - acc: 0.9747 - val_loss: 5.0578 - val_acc: 0.4959\n",
      "Epoch 427/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0775 - acc: 0.9747 - val_loss: 4.9969 - val_acc: 0.4965\n",
      "Epoch 428/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0418 - acc: 0.9858 - val_loss: 5.0679 - val_acc: 0.5000\n",
      "Epoch 429/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0381 - acc: 0.9872 - val_loss: 5.0875 - val_acc: 0.4926\n",
      "Epoch 430/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1392 - acc: 0.9576 - val_loss: 5.1467 - val_acc: 0.4835\n",
      "Epoch 431/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1750 - acc: 0.9488 - val_loss: 4.9347 - val_acc: 0.4931\n",
      "Epoch 432/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0751 - acc: 0.9748 - val_loss: 5.0196 - val_acc: 0.4894\n",
      "Epoch 433/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0434 - acc: 0.9858 - val_loss: 5.0605 - val_acc: 0.4936\n",
      "Epoch 434/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0521 - acc: 0.9826 - val_loss: 5.0566 - val_acc: 0.4976\n",
      "Epoch 435/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1119 - acc: 0.9636 - val_loss: 5.0683 - val_acc: 0.4953\n",
      "Epoch 436/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1155 - acc: 0.9630 - val_loss: 5.0604 - val_acc: 0.4847\n",
      "Epoch 437/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0777 - acc: 0.9740 - val_loss: 5.1060 - val_acc: 0.4946\n",
      "Epoch 438/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0686 - acc: 0.9779 - val_loss: 5.0751 - val_acc: 0.4961\n",
      "Epoch 439/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0553 - acc: 0.9818 - val_loss: 5.1465 - val_acc: 0.4918\n",
      "Epoch 440/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.1096 - acc: 0.9636 - val_loss: 5.1303 - val_acc: 0.4891\n",
      "Epoch 441/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.1218 - acc: 0.9632 - val_loss: 5.0304 - val_acc: 0.4922\n",
      "Epoch 442/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0647 - acc: 0.9778 - val_loss: 5.0505 - val_acc: 0.4924\n",
      "Epoch 443/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0479 - acc: 0.9841 - val_loss: 5.1068 - val_acc: 0.4897\n",
      "Epoch 444/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0840 - acc: 0.9731 - val_loss: 5.1114 - val_acc: 0.4916\n",
      "Epoch 445/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.1156 - acc: 0.9629 - val_loss: 5.0290 - val_acc: 0.4912\n",
      "Epoch 446/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1164 - acc: 0.9622 - val_loss: 5.1000 - val_acc: 0.4899\n",
      "Epoch 447/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0534 - acc: 0.9823 - val_loss: 5.0965 - val_acc: 0.4922\n",
      "Epoch 448/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0717 - acc: 0.9769 - val_loss: 5.1140 - val_acc: 0.4925\n",
      "Epoch 449/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0666 - acc: 0.9782 - val_loss: 5.1109 - val_acc: 0.4922\n",
      "Epoch 450/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0584 - acc: 0.9810 - val_loss: 5.0895 - val_acc: 0.4905\n",
      "Epoch 451/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0865 - acc: 0.9718 - val_loss: 5.1823 - val_acc: 0.4925\n",
      "Epoch 452/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1605 - acc: 0.9500 - val_loss: 5.1003 - val_acc: 0.4869\n",
      "Epoch 453/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0653 - acc: 0.9782 - val_loss: 5.0485 - val_acc: 0.4969\n",
      "Epoch 454/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0259 - acc: 0.9918 - val_loss: 5.0867 - val_acc: 0.4992\n",
      "Epoch 455/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0307 - acc: 0.9900 - val_loss: 5.1083 - val_acc: 0.4940\n",
      "Epoch 456/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0343 - acc: 0.9887 - val_loss: 5.2035 - val_acc: 0.4904\n",
      "Epoch 457/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2260 - acc: 0.9363 - val_loss: 5.0997 - val_acc: 0.4886\n",
      "Epoch 458/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0906 - acc: 0.9703 - val_loss: 5.1371 - val_acc: 0.4901\n",
      "Epoch 459/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0635 - acc: 0.9793 - val_loss: 5.0664 - val_acc: 0.4944\n",
      "Epoch 460/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0484 - acc: 0.9845 - val_loss: 5.1651 - val_acc: 0.4974\n",
      "Epoch 461/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0416 - acc: 0.9864 - val_loss: 5.1774 - val_acc: 0.4960\n",
      "Epoch 462/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0838 - acc: 0.9741 - val_loss: 5.1866 - val_acc: 0.4862\n",
      "Epoch 463/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.2186 - acc: 0.9373 - val_loss: 4.9558 - val_acc: 0.4949\n",
      "Epoch 464/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0644 - acc: 0.9788 - val_loss: 5.0250 - val_acc: 0.4920\n",
      "Epoch 465/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0309 - acc: 0.9899 - val_loss: 5.0818 - val_acc: 0.4982\n",
      "Epoch 466/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0117 - acc: 0.9971 - val_loss: 5.0634 - val_acc: 0.5024\n",
      "Epoch 467/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0070 - acc: 0.9988 - val_loss: 5.1321 - val_acc: 0.4999\n",
      "Epoch 468/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0068 - acc: 0.9985 - val_loss: 5.2166 - val_acc: 0.4981\n",
      "Epoch 469/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0037 - acc: 0.9997 - val_loss: 5.2426 - val_acc: 0.5006\n",
      "Epoch 470/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0028 - acc: 0.9998 - val_loss: 5.2708 - val_acc: 0.5012\n",
      "Epoch 471/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0025 - acc: 0.9997 - val_loss: 5.2964 - val_acc: 0.5006\n",
      "Epoch 472/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.4895 - acc: 0.8972 - val_loss: 4.1242 - val_acc: 0.4668\n",
      "Epoch 473/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.2764 - acc: 0.9159 - val_loss: 4.3457 - val_acc: 0.4937\n",
      "Epoch 474/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0492 - acc: 0.9852 - val_loss: 4.5784 - val_acc: 0.4971\n",
      "Epoch 475/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0181 - acc: 0.9961 - val_loss: 4.6793 - val_acc: 0.5028\n",
      "Epoch 476/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0084 - acc: 0.9990 - val_loss: 4.7605 - val_acc: 0.5005\n",
      "Epoch 477/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0051 - acc: 0.9997 - val_loss: 4.8645 - val_acc: 0.5074\n",
      "Epoch 478/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0040 - acc: 0.9998 - val_loss: 4.9123 - val_acc: 0.5038\n",
      "Epoch 479/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0041 - acc: 0.9996 - val_loss: 4.9824 - val_acc: 0.5012\n",
      "Epoch 480/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0035 - acc: 0.9997 - val_loss: 5.0382 - val_acc: 0.5051\n",
      "Epoch 481/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1351 - acc: 0.9677 - val_loss: 4.9908 - val_acc: 0.4627\n",
      "Epoch 482/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4142 - acc: 0.8871 - val_loss: 4.2467 - val_acc: 0.4926\n",
      "Epoch 483/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0552 - acc: 0.9835 - val_loss: 4.4787 - val_acc: 0.4970\n",
      "Epoch 484/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0251 - acc: 0.9935 - val_loss: 4.6390 - val_acc: 0.5017\n",
      "Epoch 485/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0156 - acc: 0.9969 - val_loss: 4.7329 - val_acc: 0.5021\n",
      "Epoch 486/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0159 - acc: 0.9962 - val_loss: 4.8428 - val_acc: 0.4982\n",
      "Epoch 487/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.1378 - acc: 0.9585 - val_loss: 4.8744 - val_acc: 0.4873\n",
      "Epoch 488/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.2166 - acc: 0.9327 - val_loss: 4.5538 - val_acc: 0.4962\n",
      "Epoch 489/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0583 - acc: 0.9822 - val_loss: 4.7209 - val_acc: 0.4946\n",
      "Epoch 490/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0403 - acc: 0.9877 - val_loss: 4.7565 - val_acc: 0.4984\n",
      "Epoch 491/500\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.0116 - acc: 0.9976 - val_loss: 4.8435 - val_acc: 0.5032\n",
      "Epoch 492/500\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.0071 - acc: 0.9990 - val_loss: 4.9304 - val_acc: 0.5005\n",
      "Epoch 493/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0062 - acc: 0.9991 - val_loss: 4.9797 - val_acc: 0.5011\n",
      "Epoch 494/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0033 - acc: 0.9998 - val_loss: 4.9983 - val_acc: 0.5037\n",
      "Epoch 495/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0027 - acc: 0.9998 - val_loss: 5.0292 - val_acc: 0.5039\n",
      "Epoch 496/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0332 - acc: 0.9910 - val_loss: 5.2961 - val_acc: 0.4728\n",
      "Epoch 497/500\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.4869 - acc: 0.8742 - val_loss: 4.2626 - val_acc: 0.4903\n",
      "Epoch 498/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0646 - acc: 0.9794 - val_loss: 4.4947 - val_acc: 0.4959\n",
      "Epoch 499/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0224 - acc: 0.9945 - val_loss: 4.6415 - val_acc: 0.4963\n",
      "Epoch 500/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0118 - acc: 0.9979 - val_loss: 4.7486 - val_acc: 0.4957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f229aa841d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "設定要訓練的 Epoch 數\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1976,
     "status": "ok",
     "timestamp": 1574578296997,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "Eb-KY0nYHNq2",
    "outputId": "21027f48-1db9-4b0d-beca-7025c0679a85"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3hWRfbHP5M3vXcICRBa6IRelCZF\nURSwUsS2Krtr74u79vLTddVVV9RF114QuyiCoiAdCb2H0ANJCKT3Nr8/5q0pECAhJDmf58mT986d\nO/e85X7vmTNn5iqtNYIgCELjx62hDRAEQRDqBhF0QRCEJoIIuiAIQhNBBF0QBKGJIIIuCILQRBBB\nFwRBaCKIoAuCIDQRRNCFRodSaolSKlMp5dXQtgjCuYQIutCoUErFAsMADUw4i+d1P1vnEoTTRQRd\naGxcD6wG3gdusBUqpXyUUi8ppQ4opbKVUsuVUj7WfUOVUiuVUllKqUNKqRut5UuUUrc4tXGjUmq5\n07ZWSt2ulNoN7LaWvWptI0cptU4pNcypvkUp9Xel1B6lVK51f2ul1Cyl1EvOb0Ip9b1S6t76+ICE\n5osIutDYuB74xPp3kVKqhbX8RaAfcB4QCjwEVCil2gI/Af8BIoDewMZTON8kYBDQzbq91tpGKPAp\n8IVSytu67z5gKnAJEAj8CSgAPgCmKqXcAJRS4cAY6/GCUGeIoAuNBqXUUKAtMFdrvQ7YA0yzCuWf\ngLu11oe11uVa65Va62JgGrBIa/2Z1rpUa31ca30qgv6c1jpDa10IoLX+2NpGmdb6JcAL6Gytewvw\niNZ6lzZsstb9A8gGRlvrTQGWaK3TzvAjEQQXRNCFxsQNwM9a62PW7U+tZeGAN0bgK9O6hvLacsh5\nQyn1gFJqhzWskwUEWc9/snN9AEy3vp4OfHQGNglCtchAj9AosMbDrwEsSqlUa7EXEAxEAUVAB2BT\npUMPAQNraDYf8HXabllNHftypNZ4+UMYT3ub1rpCKZUJKKdzdQC2VtPOx8BWpVQ80BX4tgabBOG0\nEQ9daCxMAsoxseze1r+uwDJMXP1d4GWlVCvr4OQQa1rjJ8AYpdQ1Sil3pVSYUqq3tc2NwBVKKV+l\nVEfg5pPYEACUAemAu1LqMUys3MY7wNNKqU7K0EspFQagtU7GxN8/Ar6yhXAEoS4RQRcaCzcA72mt\nD2qtU21/wOvAtcBMYAtGNDOAfwJuWuuDmEHK+63lG4F4a5v/BkqANExI5JOT2LAQWAAkAgcwvQLn\nkMzLwFzgZyAH+B/g47T/A6AnEm4R6gklD7gQhLODUmo4JvTSVsuFJ9QD4qELwllAKeUB3A28I2Iu\n1Bci6IJQzyilugJZmMHbVxrYHKEJIyEXQRCEJoJ46IIgCE2EBstDDw8P17GxsQ11ekEQhEbJunXr\njmmtI6rb12CCHhsbS0JCQkOdXhAEoVGilDpQ0z4JuQiCIDQRRNAFQRCaCCLogiAITQQRdEEQhCaC\nCLogCEIT4aSCrpR6Vyl1VClV3ZKgWFeVe00plaSU2qyU6lv3ZgqCIAgnozYe+vvAuBPsvxjoZP2b\nAbx55mYJgiAIp8pJ89C11kutT1qviYnAh9YFh1YrpYKVUlFa65Q6slEQBKFB0FqTdDSPDQezOJZf\nzPBOEfSIDiItp4j5W1LILy7D38ud64bEYnFTVY7fkZLD5uQsjueXcO2gtgT5eJCRX0Kon2e92FsX\nE4uicV0TOtlaVkXQlVIzMF48bdq0qYNTC4Ig1B/P/riDd5bvs2//sS+DV6f04Yo3VnI4y/GMkl6t\ng4kJ8eH5+Tu5qEdLLurekjl/HGTm11vsdTwtblzcM4px/17K3y7uwvTBbevc3rM6KKq1nq217q+1\n7h8RUe3MVUEQ6piF21IpLClvaDPOWfYdy6e0vKJKeV5xGR+uOsCwTuF88Zch9G8bQlFpOT9sPsLh\nrEI+unkgX/5lCABZBSU8NW87X284zOPfbQPg242HaRPqy6L7htM61Ic1+zJ4+edEyio0I+LqR//q\nQtAPYx6OayPGWiYIQgOz9XA2f/5oHU98v61O29Va89OWFIpKzY3ij30Z/OfX3XV6jrPB/mP5jH5p\nSRWPG2BZYjol5RXccUFHBsSG4unuRlm5ZktyNsG+HgztGE6YvxcAx3JL+GV7GgD5xWWUlVewOTmb\nUV0i6RgZwJD2YSTsz2DL4SzO7xhO61DfKrbUBXUh6N8D11uzXQYD2RI/F4Rzg+RMI1KbkrPILSol\nduaPzNt0pMb6X65L5vZP19u3Z3yYwDvL9laptyk5m79+sp6ZX20mLaeIa/67ipd+SeTj1Qe4Z84G\nsgtKa23j/C0pbE7OqnH/oYwCXv4lkdLyCo7mFnH/3E0u7T/67VbGvvw7BSVlfLByf7VtFZaUV+uF\nb0/JoULDlsPZ/G/ZPvKLy3j0260s2JrK2v2ZeHu40a9tCAAeFjdKrULdMzoIpRTBPh4ArNp7nOKy\nCjpE+JFXUsam5CwKSsrp0yYYgHB/L7IKSzlwvIB24fUj5lCLGLpS6jNgJBCulEoGHgc8ALTWbwHz\nMc9sTAIKgJvqy1hBaCqk5xYT6OOOl7vljNv6aNV+Plx1gB/vGoanu6uPtv94PgCFpeVsP5IDwBtL\n9nDgeD5zE5L5+OZBtAnzpbxCk1dcxgNfbALgtSma5UnH+Hl7Gj9vT+OWYe1d2t2bngfAtxuPEBvu\nZy9/e9leDhwvIK5lALeN7FitvRUVmpLyCrw9LJSVV3DbJ+YGsvPpcRw4XkDnlgEu9Ye9sBiA4Z3C\n+WlrKl+tT6Z9hB8XdI6ksLScj1abtaoS0/J43NoT2fHUOMq15psNh5k6oDVdH1vAuO4t+cf4rny1\nPpmbzm9HTmEpu9PyUAqCfTzIKSrl5V8S+Wj1AdYfzMTPy51uUYG4W8xn6mFRlJZr9h3LZ0iHMAAC\nrYK+NDHd2BgXwZ70fN5dvh8fDwujukQC4G5xQ2soLqtw+bzqmtpkuUw9yX4N3F5nFglCI2f57mPM\nTTjEK5N741ZN5sORrELOe/43/jy8PQ9f0tVeviU5m+82Hubvl3RlWdIxHv5qMz/fNwJ/L3eSjubi\nphTtI/xd2ioqLedRa8w2LaeoSld+X7oR9JSsIhKPGhEO8fXgp62pHMwo4LO1B/nLiA7EP/kzl/eJ\nth+3MzWHG979w6Wt91fsI8TPk4m9o0mytgWwZFe6/XWBNVa/Oy3P5diVe46x/UgOtwxrz6zFSby8\nKJHbR3bkwu4t7HWu+98a1u7PZM6MwXSM9Cfc34vjecWO93Is3+59r957nH8t3OVyjhVJx+yvE9Ny\n+XbjYd5bsZ/CkjIAFmxLxc/Lna/WJ/PKIhMeGt8zipgQHzwsbmTml7BwW6r9sywqreCKvo7PxOah\nF5aW4+dpbsQWN0WAtzvH80sA7N/P0t3pnNchjABvI/geTr+DdmENKOiCcC6TVVDC1LfX8Nil3exe\nU0Pz+Pdb2ZOez5SBrTmvQ3iV/bOXmhDGhoNZjHtlKR0i/bl7dCemvb2a3OIyxveK4sWFuziSXcTa\nfRlc0CWSMS8vBYwX+/3GI3y1PpnOLQO46fx29naP55dUEfQDGUbQS8or2HTIiKHFTVFojX3vS8/n\ng5X7Afhmg2PoKzEtt4rdT8zbDkD/2FD2pDsE2/l1eq4R4KSjeZRXaCq0JjO/hGlvrwHg2kFtmbP2\nEFrD64uT7EIIsHZ/JgBTZq8myMeDBfcM4+DxAvv+/cfz2ZFi7Npm7W04Y/OSAZYnHeOjVcZz/2TN\nQXt55bDLoh1pDGwXSmZBCcuTjlFcVsHQjuEst94c2jl50+4WN/sNy8vD0bMK9vUgt8jcNEJ9TTpi\nblGZ3Xu3HWsj1L9+UhZBpv4LjZwv1yWzIyWH//x26gNyC7amkOEkKKdKWk6R/fW6A5mUWcWiVbAP\nYGLD1WHzJHOKStmZmsuPm1N4ZVEiucVWT3JrKi0CzWDbH/sz7AOPAE/O28ZDX21mzb4MPlx1wMVT\nPmYVU601e9Lz2JycxdFch4e7I8WI4NGcYo5YBwD3H89n46GqMeddqa4edkq2Y8AwYX8GBzMKCfAy\n/mBuURkhvh4u9ZOO5vHnj9YR/+TP3Dd3k718bsIhDmcVcu0gk7a8PCnd5TgPi/FkswtLeejLzfZe\nhae7G9uO5JBXXEawr4fL99Yx0njF6w9m2nPBX/4lETdlXh9wuiks3nkUHw8Ln9wyCDAhkDA/T3w9\n3Ckuq8BNwdSBjpRqfy+Hz+thUeRZvyMvp9BWsI8RaE+LGwHejvo+nhaXY224u9Wf7IqgC40amzhm\nF9ZuEK6otJzkzALSc4v5y8frGfjsImp6rq7WmuKycsorzP6jOUVsOpSF1pqVSccY9H+/snBbKst2\np3Plmyv50OoRZlkH7LYfyaGkrIJDGQ5BOZ5XzG6rSB1xyqpITHP2ePNJzzOC9eaSPUx7e7V938o9\nx11s3Hgo0/76mDU8ccdnGxj90u9MeH0FadlFBFpFxpbFsfdYHkWlFVjcFPuO5bt42A57XD305bsd\n4Yy752xkR0oOfayDhQCRAd72154WNwpLy1m0I42CknKWJx3jqn4xALyxJAnAvn0owzWzxFbev20I\ny3YfY97GI/h5WjivQxhr9mYAMDA21F7/yQnd+ea28wAoLdd0jPDHx8NCeYWme3QgYdYJPPExQQDk\nFpcxqH2oCYdYxTrEzxNvq/jGtQggJsTH3r6zQHu4uVUr6EFWT9zDolzq+zkJurtTyMXTIoIuNEMe\n+XYL76/Yd8I6tq7ujpQcu/CCyWpwjr/a+Mc3Wxn6z8V2z7asQtu92HmbjrBk11F73RcW7qLzIwvo\n8Pf5JB3N45r/rmLirBV8v+kIi3aYepsOZdm75zbBTMk2nntiWh6v/prIsBcWk3Q0l+KycrY6hQpy\nihzicMA6eKkUpOcVk+x0E1h/0OFB27JWbGw6lG1//ez8HexOy+W3HY73kF9STjtrXNd2oyktN5/T\neR3CKC6rcPFgbexKzcXL3Y2Pbh4IwG87j1apEx8ThNUJJtLaowDo3Tq4St3rBrclKsibtJxiurcK\npEvLQPu+DhGOsMaF3Vqy9MELeGVKb8D0UDpG+tMu3M8eJhrU3hFaC/b1wN/L3S6YYf6eRAWZm0vP\n6CB7b6lv2xBah5rXUUHeKKXsoY9QX098rSGUiAAvF1H293L0PDzclf035jyYbfPiPdzd7DFzAB9P\nRzsWJxF3t1QdV6krRNCFc5KCkjI+Xn2QJ+Ztp7jMdVLMgq2pvPTzLnKLSsm3xjQrNC6hiSmzV9Hv\nmUVV2rUNen2R4JjcfCijgLziMu78bAM3vreW/OIyftmexpw/HLHXeZuOsN8qfG8u2WMPX2xOzma1\n1WvOLSqlqLScY3nFRAZ4kVds3gPAmJeX0vmRBfzdOnPQ5jECtAn1tYtsXGQA+9LzOJ5fYhcmG9HB\nPnZB+eeVPQFzQ3EOfYz991IKS8u5YYhjFmIHpziwj1Pst28bh4cdbA2Z2LzNw1mFtAzytmec/LQ1\nlfBKsd+YEB972l6LQIetvdu4Crqbgl4xQfS1evSX94nGx9Ni92C7tXJ8Fv7e7rQJ8yU62Mf+/jtG\nBrjEsp099FA/T5M+aI1dh/l70TXK3Cz6x4bS0/o5x8cEM7hdmP1zBIenHOLnia/VliAfDxdR9vNy\n9rIdcunl4Xhtyyxyd3Oz94YAe5vgOigqgi40SrTWzF66xz5Q5syhjIIqQu3M5mSH57nhoGuM95kf\nt/Of35L4cXMKBdYMBsDuwYHJkwb4dUeavSy3qNTeZf7RKb59MKOAhVtT7duXv7GCWz9MINMp13mu\n9QYQ5ufJkaxCth4x7S9POmY/16GMQp750QwcXtIzCjChoFZOwnw4q5CIAC9iQhyDl22cBjI7tvC3\ne+6PXtrN5X33jDbi1DLQm4m9TfZFbnEZUcGuwg9wVT/HXD/nNLk4p5TAfk4hk/gYI8LdWzk855gQ\nHyIDvIkMMN53r5hgl/VKIgO97eIXEeDlcpyN16f1YeXM0Sil+NtFXZjcvzXTrPHz4rKKKuf0s3q1\nSin7gHKonwexTpkhsU553CFWIbfF8MP8PHltah9+u38El/aM4tlJPUh4ZAwTe7fiiQnd+c/UPvYp\n97aByhBfT3u8O9DHw8VDd37tnBLqHHKxlXtalOvNwDnk4uShS8hFaJRsO5LD/83fyd++2uxSXlhS\nzrAXFvPgF5trOBKXySFZBaVobWboVVRoSqxCsCc9j/ziMvuA0+HMQt5eupeHv3a0e/MHCSSm5bL+\nYCZjrZki4BATgHdX7OP+LxwDd87x7BaBXgyPi7CHUfrHhpBTVEZuUZndm7VxMKOAhdvSGBEXYR/0\nA7hrdCfev2mAfbtziwAXz89ZAOMijeBGBHgxrntL/nVVL/s+2+BfkI8H3h4W+/l7RAfx093DeGS8\nIwWye6tAuxg5e7edW5g2PC1uLkLaJcqcd9qgNnbRbh9u6tpuJPExwfx09zD7McE+HnZhcx489Pdy\n572bBjDvjqFc2qsVLa03tDZhvvzzql74WkW7zNrbGG+9+VVu596xnegU6c/E3tF0strdNszXpU6I\nNUZuy+4J8/PE4mbSO93cFEopwv29UErh5+XOZfGt7N68p/V3E+LrYe+52D5bG35O53KOgzuHXGyC\n7uHu5jIQ6hxycRkUFUEXznWKy8qrDEymWkXQ9t/G9hTj0X5vnbGYkl3I499tZfGuo9zyQQJ/7Mvg\nSJbjmNyiUj5ec5DLXl/OD1tSyCwwA4Z70/PJLy4nzM94hxNnreDZ+Tv47I9DLudbtCONK95YSWpO\nERd0jqCbtUse6O1OqyBvth424ZO4Fq453gAXdI6kr1MIwdmrnX1dP2LDjJAMbh/K4axC0nOLGd01\n0mWQsGWQNyM7R3JBZ7N+x8jOEXah8Pdyt4uSu5uyx3kv6ByBm5tySX1rb401B1m9UduNoFtUIF2j\nAhnWybE+iJub4tf7RvDgRZ0Z4BSi6GyNXbcM8nZZ8e+e0XG8fX1/xveMsguX7XyPXNqN567oyY3n\nxRLXIoCvbzuPPm2C6dIyEA+rOPlUEsELOkfawx01cf/YOC6Lb+WSaunv5BHHhPjyy30j6BEdRFSQ\nD7/eP4Kf7x2OUorbRnYAsA962gTf+UZ9MmxCrJRDbAO9XW/SrlkuNYRc7BOPXOXUdVDUKYZezdyE\nukIEXTgj1uw9Tk5RKbd/soH4J392yRg5YB3YS80p4pYP1pJlFWLncEpZeQWzl+7lg1UHuOm9tSza\nkcbspXs4mltkj9nuTM3l/37cAcBdn22wx5sTj+ZSWFruIkzndwxjYLtQEh4ZYy97YYGZgDIgNoRZ\n1/a1pwRGBnrTIdIh4s4hDttAnae7G22tou2mIDrYIT5dWgZy/ZBYAJdZkQPbhRLo4xACm4c6oXcr\nwIRjbEIR4O1uj0Nb3BRRQUakR3c1E26cBcY2acXmmT81sTthfp5c2K0lgN3Ocd1b2t/f7Rd0dLEl\nOtgHX08LrYK9XYTMx9PC2G4tUErZY9C2WHO7cD+mDmxjv5H0bRPCN7edj4+nxe55+npa6GIN53jU\nMkZ85+hO/GdqH5cy555LZTpE+Ns94wcv6sz2py6ye9OX9DBefnw1A7I18fyVvRjfM4o+bYLt+ele\n7pVFuXov29lDtx1TWdB9XEIujmMr16tLZGKRcNocyihg8uzVXNE3mkXWWPXO1FzaR/jh5W5htzX1\nLSO/hEU7jvL1+sNM6N2Kl39JtLfx8eoDvLdiv0u76w9m0T7cj/bh/hzLy+DTNQcpqhRvbxvma8/O\nCHMarHtmUk97iGHVw6P4+9dbWLwrncgAL+b+eQhKObzeCH8v2of7sWz3Mf4yooOLh9u3TYhJH8wt\npk2oaS/Uz9N+rpaB3gT5enDT+bFc0TeaIB8PrukfQ1yLAJcMDoCoQCOMk3pHM75nKzzd3eweuofF\nDX+raHt7WBjULpQP/zSQYZ1M/NhZjG0es+0G0K9tKOseHWvf7+1hYemDF7hknICr9xzs60GPVkH0\nssbMX53S2yVODPDK5N48/cN2BtdiopYtfODjaeHesXH8+aN1tD2DmZC1XQpBKWUP3YAR8s1PXFjF\nwz4RHSL8mXWtecBaidVJ8Kgk6M4zfV089Gpi6DbB93R3o6SswsU+Z6+8unXT6woRdOGUeGfZXnak\n5PJ/V/Swp7IdzyshxNeDzIJSLn51GcM6hXPv2DjmrHUNfZSWV/D+iv3kFpUxbVAbPl1z0D770JmM\n/BIy8kuY2LsVvp4WCkrKiQ3ztWeZgMl0sAu6k4fu3M2NCvKhT5sQFu9Kp3PLALtHavNwIwO97MJa\nuRs8fXBbEtNyuXtMJ1pYwyd/GdHBfi7b4KJzhsULV8VX+5nZRFkphae7OY9NEHw8jGfr5e7GvyfH\n4+amGO60tKqzQAV6ezA8LoL+sSHURJuwqgs/OXviHSL8mTNjsH3bNrjqTGy4H/+7cUCV8uqwfW4+\nHhYu7N6S3c9eXK8e6Ik4FTGvjG1SmMcJxNY59u1dTcjFNpHJx8NiFfTqB0XrEwm5CNWitXYJn+QU\nmfj4rMVJfLU+mc/XHmLlHpN/7e/t7uKNLNt9jK/WJQNwy1DH1PTnftrJ64vNxJJr+juvuAzX9DcT\nSib1bmW/WCIDvOyhia5Rgfzvhv72+r2cutahfg6P1NfL1UexhSEqCyMYD31cDxOeGN010uW4uBYB\nfHfHULq0DCTEz5MdT43j5qHt7OGdLpUWkDoRzoJqw/a+bh3enh7RQex8ehyjurSoUq+ySH34p4FM\nHnDqD4e58bxY/nVVLyICvHBzU9WuMXM62MTbs4awQ2PBFh6xxfCr+3g8awi52N677Wqx9YhqSlus\nT8RDb2YkZxaQdDSPkZ0jq+zbfyyfy99Ywbs3DuDhr7ewMzWXcd1bMqRDGE/M28a9Y+LsnsaavRn2\nbJD03GKO5RVz67B23H5BR3o/9Yt9XZBbhrV3eeKLDefMiz8Pb8/Mi7swqksLRsRF0CbUl9d+SyLA\n26SQHc0tpmtUIKO7tmDVw6N4Z9k+JsS34tFvzXPLnUMuzuEFMLHo8T2jmHlxF3uZzWOODPSiV0ww\n+58fb9/XIzqQrYdzXOKf4LjgQ/08uWdMJy7t1epkHzW/3T/CPvGpMpP6RBPXIsAe861O9MEhMJVz\n0k+VJyZ0P6Pja8IWG3ae1HU6fHv7+RzNKTp5xXriwYs6E+HvxcXWWPyav4+p8lAQ95OEXGwOUMsg\nb1Jzily+07PloYugNzOuenMVqTlF9q5xfnEZ/1u+jxnD2/Pz9lQyC0p59scd7Ew18e8F21LZeywP\nrXGJfTvncf+xz0zJjgjwItjXkw4RfuxJz8fX00LLIJPHfLRSLrrzBIwOEf4opeze8j1j4mgT5scF\nnSPsYR3bQF1UkE+V/GznkEvl+KS/l7s9Tuo4d9XcaRuf3Tr4hMsIKKW4Z0xcjfudqbwyojMeFrda\nDeBZ3BRvTe9Lz5jaD/adTWzZG2VnKOjVzS49mwR4e3Dn6E727ep+G64x9Go8dOtH8Nb0fnyz4bA9\nAwrqdzKRM42zfyScNqlWL8gWf/5g1X5etj6YwLYgU8KBTJdjEtPy7IN04BDXythiibYZiLZJH3/8\nYww3D22Hj4eFy/tE8+qU3i7ey7A41xUJ3dwUV/WLIczfMQ27a1TVEIctE6VymOVk2AZFnVMLbQR4\ne7hM+jkXGNcjyp5xcq7x5MTuTOzdqt4eqXYu4ZLlUk0MXePw0P86soPLb9yjHhfkckY89CZKdkEp\n1727hnvGdLLHZp1j4m8u2cPAdiF2b3Rnqpl8079tSBVBB8fkEpMR0p6Okf78/est5BaXsde65vZQ\na5ZI91aBfLEOKpzO98j4rjwyvqvLj3zG8PYosKfqVYdt5l51gvbf6/rz1A/bXXLDa8PAdqFM7N2K\nXifJkxZOTnSwD69O6XPyik2Ak2W51LDGG1C/mS3OiKA3Ud78fQ+bk7N5bv5OekYHs+FgJo9+t9W+\n/6v1yXy1Ptm+/aV1EPPG82IJ9PHgt51H+e7285k4awVguqAPX9yVlOwN9mcpfnfHUDYdyuKt3/fw\nypTe9m5oXAvjTR9zWhyruhjx350e7lATtw5rz6U9o6o9vmOkPx/+aaDLGi61Idzfq9mIkFB3OGdC\nOf8evWoh6LXNzT9TRNCbEM//tJPM/BL+eVUvth42k3d2H81j0qwVhPp5kpZTdU0VMF6WbaXAUV0i\nmTygNRsPZbl4sBEBXnRrFcii+0a4HBvfOpg3p/dzKetkFXTbBKAzoXfr4JPGVytPBhGE+qByjrqN\nylku1SGDosIpUVRazlu/7wGM5+v8QILDWYUczipkXPeWLNyeygMXdmbNvgyemdiD+VtTGNoxHK0h\ns8DxxJvB1iVK/b3cySsuI9y/6iBRTdhmeDqnLNYnNWWICEJdUlMc3NNieqY1rasP9Tvd3+U8tamk\nlBoHvApYgHe01s9X2t8WeBeIADKA6Vrr5CoNCfVCfnGZy/MVv1yfzJ70fHrFBLlMs3/pmnieKe1B\nmJ8nt19gpqr/ZUSHE7Y9bVAbZi/da19xrzYopVxSAQWhKeDuNBPUmdrE0M9Wfv5JBV0pZQFmAWOB\nZGCtUup7rbXzFL8XgQ+11h8opUYBzwHX1YfBgpnV9sPmFPKKywjwdmfdgUw+XHWAHtGBJKbl8fQP\n5qu5rFcrZo7rwrR31jB9cBv8vNxdVo+rDTPHdWFCfKsTpuCdK1S+0AShLrGJckSl3qoj5HICD/0c\niqEPBJK01nsBlFJzgImAs6B3A+6zvl4MfFuXRgqu/HtRIrMW73Ep8/W0MPu6/ox/bZl9edlQP0+G\ndAjj3Rv7u6xTciq4uSl6RJ/72SAL7xle5bmWglCX2JYHqLxWjj1t8QQe+tkKudTGpYkGnBflSLaW\nObMJuML6+nIgQClVZWUfpdQMpVSCUiohPT298m6hElpr9lqf95h0NJdhL/zGluRsvtt4hDahvtw1\nyrHC33NX9KRVsI9L165TCzNhZ1SXFo12SnZt6dwygMjAM5tNKQgnwqbX8ZUmednW5zkXBkXr6iwP\nACOUUhuAEcBhoEoumdZ6tvYOsAYAACAASURBVNa6v9a6f0RE05+IcKZ8suYgo176nRcW7GTMy0s5\nlFHIPZ9v4HBWIZf3iebPTvFv22Set67rx3WD27LpsQvtK+oJgnDmDGoXyuvT+vDwJV0q7bEKeiMZ\nFD0MOK+kFGMts6O1PoLVQ1dK+QNXaq1dnxsm1IryCs3m5Cw6twzgPesDkt9Y4giv7LFO4mkX7ucS\nD7c97KBvmxCXZ0UKglA3KKWqXcPHlmR1Ig/9nBkUBdYCnZRS7TBCPgWY5lxBKRUOZGitK4CHMRkv\nwimgteanrankF5fx4Jeb6RUTxJ70fHw8LBSWlhMV5M3vD15A3CM/AY7nRA5sF0pFhZbUPUFoIGzr\n0w8/wTjVOTNTVGtdppS6A1iISVt8V2u9TSn1FJCgtf4eGAk8p5TSwFLg9nq0uUkyb3MKd322wb5t\nSzec1Ceaz/44iMVN4enuxrOX9+D5+TvpZH3Sztw/D2kQewVBMIT5e7HsoQvsT6ZqSGqVw6a1ng/M\nr1T2mNPrL4Ev69a05oXz0+mdudwq6NdZn1R+7aC2TBvYRjxyQTiHcH4uakMiM0XPAZbtTue7jUfs\n25N6t+Jb63Z86yC2PXmRy2L5IuaCIFSHCHoDkZlfwj++3cKA2FCO5hbbR8HLKjT3je3MBV0iiQ0z\nz+Y8xblAgiCcg0yIb8XIzvWb3SdS0UC8v3I/87ekMn9LKgCdIv15ZlIP1uzLoE2Yb7XPhhQEofHy\n2tT6X+FTBP0sk5iWy9VvraryVBw3pRjUPoxB7U/+pHVBEITqaNrTB89B1uw9bhfzoR3DmTLApPhf\n0jOqIc0SBKEJIB76WURrzc7UXHw9LUwd2Iar+8fQpWUg/xjfFV9P+SoEQTgzREXOEusOZPLQl5vY\nk55PTIjrg44DvGVRKUEQzhwR9HqkokLzwar9RAZ4c/un6wn398LL3Y1JvSuvbSYIgnDmiKDXI6v3\nHufJeWaV4YgALxbdO4IAb3fcztI0YEEQmhci6PXIrrRc++sbz4slSNbrFgShHpEsl3pki/VBzV7u\nbvZsFkEQhPpCPPR6YE96Hv5e7vy64yjD4yJ47NJuhJ3CQ5YFQRBOBxH0Ombt/gyufmsVAG4KHrgw\njo6R5/7zOAVBaPxIyKWOmb8lBYDOLQL45rbz5alBgiCcNcRDr0OKSsv5YXMKo7tE8r8bBzS0OYIg\nNDNE0OuIt37fw/M/7QTgT0PbNbA1giA0RyTkUkfYxBzgvA6ywJYgCGcfEfQ6YEXSMfvrG8+LlQdQ\nCILQIEjI5QxZmXSMm95bS0SAF29N70evmKCGNkkQhGZKrTx0pdQ4pdQupVSSUmpmNfvbKKUWK6U2\nKKU2K6UuqXtTzz201jw7fwdRwd78cu9w+rUNwcMinR5BEBqGk6qPUsoCzAIuBroBU5VS3SpVewSY\nq7XuA0wB3qhrQ89Fftt5lG1Hcrjjgo4E+3o2tDmCIDRzauNODgSStNZ7tdYlwBxgYqU6Ggi0vg4C\njtAMeG/FfqKDfZjUR1ZPFASh4amNoEcDh5y2k61lzjwBTFdKJQPzgTura0gpNUMplaCUSkhPTz8N\nc88ddqflsjzpGJP6tJIwiyAI5wR1pURTgfe11jHAJcBHSqkqbWutZ2ut+2ut+0dE1O/Tr+sTrTV/\n+mAtABPixTsXBOHcoDZZLocB56UCY6xlztwMjAPQWq9SSnkD4cDRujDyXCIjv4S+T/8CwH1j4+jc\nMqCBLRIEQTDUxkNfC3RSSrVTSnliBj2/r1TnIDAaQCnVFfAGGndMpQbWH8i0vx7VJbIBLREEQXDl\npIKutS4D7gAWAjsw2SzblFJPKaUmWKvdD9yqlNoEfAbcqLXW9WV0Q7IzNcf+WrxzQRDOJWo1sUhr\nPR8z2Olc9pjT6+3A+XVr2rlHYUk5vyemEx3sw7w7h8pgqCAI5xSiSLWkpKyCK99cydr9mfxpaDtC\n/STvXBCEcwuZ+l9L5iYcYntKDq9N7cOE+FYNbY4gCEIVxEOvBVpr3l2xj/jWwVzWK6qhzREEQagW\nEfRasOFQFnvT87lucFtZSVEQhHMWEfRa8PO2NCxuirFdWzS0KYIgCDUign4Sftmexlu/72FgbChB\nvh4NbY4gCEKNiKCfAK01/zd/B7FhvrwypXdDmyMIgnBCRNBPQHJmIfuO5XPzsPa0CPRuaHMEQRBO\niAj6CdiRYmaFdm8VeJKagiAIDY8Ieg1orZmbcAiloItM8RcEoREggl4DX6xLZtGOo8THBOPrKfOv\nBEE49xFBrwatNW8sTqJrVCBf/mVIQ5sjCIJQK0TQq2HdgUz2Hy/glqHtcJcFuARBaCSIWlXDj1tS\n8HJ3Y1yPlg1tiiAIQq0RQa/E7rRc3luxnyEdwvDzkti5IAiNBxH0Svztq80AXNZLVlQUBKFxIYLu\nRGp2EesPZnHbyA5c2S+moc0RBEE4JUTQnVi22zwGdUJv8c4FQWh81ErQlVLjlFK7lFJJSqmZ1ez/\nt1Jqo/UvUSmVVfem1j/rD2YS6O1OXKRMJBIEofFx0lE/pZQFmAWMBZKBtUqp763PEQVAa32vU/07\ngT71YGu9kl9cxrLdx+jbNgQ3N1nzXBCExkdtPPSBQJLWeq/WugSYA0w8Qf2pwGd1YdzZ5M0leziS\nVciN58U2tCmCIAinRW0EPRo45LSdbC2rglKqLdAO+K2G/TOUUglKqYT09PRTtbVeWbgtlSEdwhjZ\nObKhTREEQTgt6npQdArwpda6vLqdWuvZWuv+Wuv+ERERdXzq02d3Wi67j+YxRp5IJAhCI6Y2gn4Y\naO20HWMtq44pNMJwy2d/HMLDopgQL9ktgiA0Xmoj6GuBTkqpdkopT4xof1+5klKqCxACrKpbE+uX\notJyvlqfzEXdWxLm79XQ5giCIJw2JxV0rXUZcAewENgBzNVab1NKPaWUmuBUdQowR2ut68fU+uGn\nrSlkF5YybWCbhjZFEAThjKjVYiVa6/nA/Eplj1XafqLuzDo7aK35ePVBYsN8GdIhrKHNEQRBOCOa\n9UzRL9Yls+5AJjcPa49SknsuCELjplkL+oKtqbQL92P6IAm3CILQ+Gm2gl5RoVl/MJOBsaHinQuC\n0CRotoK++XA2WQWl9Gsb0tCmCIIg1AnNUtB3p+Vy03t/EODtzrie8lQiQRCaBs3ykTyLdx0ls6CU\nVyb3JtDbo6HNEQRBqBOapYd+KKOQIB8PJvWpdkkaQRCERkmzFPSDGQW0DvVpaDMEQRDqlGYp6Icy\nC2gT6tvQZgiCINQpzU7Q03OLSc4opE2oX0ObIgiCUKc0O0F/9ddENJqr5CHQgiA0MZqVoOcXl/HN\n+sNMiI+mY6R/Q5sjCIJQpzQrQV+0I438knKu6S/euSAITY9mJegLt6USEeDFgNjQhjZFEAShzmk2\ngp5dUMqiHUe5uEdL3Nxk7RZBEJoezUbQP/3jICVlFVzdr/XJKwuCIDRCmoWgZxeW8tqvuxndJZKe\nMUENbY4gCEK90CwE/edtqRSWlnPHqI4NbYogCEK90SwEfcHWVGJCfOjdOrihTREEQag3aiXoSqlx\nSqldSqkkpdTMGupco5TarpTappT6tG7NPH2KSstZuec4o7tEyoMsBEFo0px0+VyllAWYBYwFkoG1\nSqnvtdbbnep0Ah4GztdaZyqlIuvL4FMlYX8mhaXljOgc0dCmCIIg1Cu18dAHAkla671a6xJgDjCx\nUp1bgVla60wArfXRujXz9Fmy6yie7m4Mbh/W0KYIgiDUK7UR9GjgkNN2srXMmTggTim1Qim1Wik1\nrrqGlFIzlFIJSqmE9PT007P4FPk9MZ2BsaH4ejbLZ3kIgtCMqKtBUXegEzASmAq8rZSqMgKptZ6t\nte6vte4fEVH/IZDU7CJ2H81jeFx4vZ9LEAShoamNoB8GnGfjxFjLnEkGvtdal2qt9wGJGIFvUJYn\nHQNgaEeJnwuC0PSpjaCvBToppdoppTyBKcD3lep8i/HOUUqFY0Iwe+vQztNi+e50wv096dIyoKFN\nEQRBqHdOKuha6zLgDmAhsAOYq7XeppR6Sik1wVptIXBcKbUdWAw8qLU+Xl9G1watNcuTjnNeh3BZ\nu0UQhGZBrUYKtdbzgfmVyh5zeq2B+6x/5wTrD2ZyLK+YEXESbhEEoXnQZGeKfrnuML6eFsb1aNnQ\npgiCIJwVmqSga61ZmpjOiLgI/LwkXVEQhOZBkxT05MxCDmcVMqSDTCYSBKH50CQFfdUeMx4rs0MF\nQWhONElBX733OGF+nnSSB0ELgtCMaHKCXl6hWZ50jMHtw2R1RUEQmhVNTtB/23mUo7nFXNorqqFN\nEQRBOKs0QUFPI9DbnbHdWjS0KYIgCGeVJifo21Ny6dYqEHdLk3trgiAIJ6RJqV55hSYxNZeuUYEN\nbYogCMJZp0kJ+t70PApLy0XQBUFoljQpQV+9LwOAgbGhDWyJIAjC2adpCfqe40QFedM2zLehTREE\nQTjrNBlB11qzeu/x08s/19r8CYIgNGKajKDvPprH8fwShtim+696A3553LVSzhGY/yDkmycZsXku\nfHQFvDUM5l53dg0WBEGoY5rMUoS29VvsC3Jt/w5SNsEF/4Df/wnLXnRU/mM2DPorrHnTUZa2BdIT\nYekL4O4Fyetg/EsQe77riRY9AcoNRj+GIAjCuUSTEvToYB9ah1rj57kpUFYIH02CAyuqHmAT82s+\nhJwUWPA3+OhyyEl21Jl3F/SaAhVl0KIbHFwNq98w+0TQBUE4x2gSgl5RoVmz7zijurSAshIozIS8\nNLPTJuZ9roNRj8LLXUGXg4cvRHaFbhOhrBgWzDRiHjcORs6ErV/Dytdg8TPVnzR9F/hFgFJQkGGE\n/oJ/gG8tMmxSt0LBcWg/om4+AEEQBJqIoO9KyyWzoNSEW5a9aEIszlz8Agz6s3k9YwkcS4S4i0zo\nBEyIxcbgv0KrPibevvK1qie77FWYdzfMGugo8/CF0gIj8CNnmrLje2D5yzDmKdjwEbQ9Hzz9wDsQ\n3rKGcR7LBLcmM4whCEIDUytBV0qNA14FLMA7WuvnK+2/EfgXcNha9LrW+p06tPOEuMTPP/2haoVu\nkxyvo3qZv8pM/gjW/g/aDjXbcRfD1Dmw5UvY+iVM+Qx8w6BFd1j3PhzZ4Dg2PA7KimDJc6As0Ge6\nEfyKMjj0h7mBVEfC/2Dgraf+hr+73dw8xjxx6scKgnDmFGXDp5NNrzy4NYTENrRFACh9knQ9pZQF\nSATGAsnAWmCq1nq7U50bgf5a6ztqe+L+/fvrhISE07G5Crd+mMCu1FyW3jsYnmsNFaVmx4TXwScE\nul56+o0X58KexdBtgmt52nb47jaY/AkERZvtz6ZA1oGqbSg30BXVtx/UBobdB7t/htQtMPUzaNkT\nKsph9ZvQeiDEDDChHTDplU8Gm9exw6D3tdB76um/v8bKzvnQcbRr70qoSlmx+R31ngb+kQ1tTeNj\n/3LwDoKIrpCfDgEtTYj1/Usgfaej3m2rTU89ea0J41o8YO/vsG8pFGVB0q9w9fvQqvcZm6SUWqe1\n7l/dvtp46AOBJK31Xmtjc4CJwPYTHnWWqKjQ+OxdyGfe38AbpUbML37BfBHdJ4FXwJmdwCugqpiD\nGSSdscR1++afrTF6q3hHdIX0HdBrMmz6zJTFXQyJP0GrvnBkPWQfhB/ucbTzzV/BJ9jciHZ8b8p8\nQoxwF+cYIbOxf5n5S91i9rUfCT2vcuzf8xt8dwf0vcHcNFI3Q3S/qu9l+SuQfchk9ZyI+Q9CmyHQ\n44oT16stFRWw9m3z3gqO1d7LObgG5kyFwbfBmCdh/gMQ0QWG3HZm9hTngdcJHopSXgqbP4d2wyG4\nzam3XVoI/hGQfdiM8UT3PTN7bWgNJfnV2/7TQ6ZHqRScf/eJ2ykvg+3fQljH6oVn9yLzW4yp9Bv6\n+VE4tAYmvWl6rt0vN+NY7l41X38HVhnPNiimVm/RTto2+Pw6uOF7+HoGBERBeQn0u9Hc4ME4YbW9\n7ovzYM1b5ni/cPNZlpcY23NT4f3xrvUHzgCLp6uYA2Tuh2//at53zhEYcjt8fKXDuQRzvdeBoJ+I\n2gh6NHDIaTsZGFRNvSuVUsMx3vy9WutDlSsopWYAMwDatDnFC6IGdqXlcn3Ft0QX7YYia2GPqxwx\n87NJQEsz8Prrkybs0v4C+OpmiOwGHUabgVA/a1plr8lGHDd/bsTMRtqWqu2GdoBVr9d83tWzzP8N\nH0HiQrj8LZO2+cM9pmu47EWzL/sQ3LURQtuZ9MvjSXDFO7DImq9v8YIxj1f1erU2N4M/Zps/70DY\nMQ+G3W+ErbwM1r4Dfa+HnMOmR+LuBb89Cxf/E1I2GjFs0QPyj5oeCJheyU8PmT+A676FDheY17mp\nsOsn6HGlOd/O+WYMov0IRy/oyEYzaL3+A7Md3Bq6XOrozeSmwaZPYcidZiC8Om++pAAS3oW0ream\n+0ASvNjRvJf849D/T5B7BDqPh8XPmjBZUGvoMMp4ZN0mQNvzzGC8u6f5rHb/Ysq8/E3q7MbPjOd2\nOAEe2A3/7mbOffdmc9GPew46jYXSIvDwNm39d5hp68+/g4eP+R4ryo1Ybf8Wju6AAbeY/9/fYT7z\nh/YZZ6AwywhMSb7pXYLJ5HJm8xfme7nwGfN5VVSYUN7mOeDuDQ8nm/Md3+34vj650vx/wmpL4gKI\nGegYa5o90jgWy16Co9shMNqEKGOHGbHNOmTGpzz94L1xENoe7toAe5eYuiGxJhmhOMd87m4WMxa1\nYCYEt4Vxz5ubU8Ye2PCJa/Zaxl5zjvUfwfd3Gufk6HboOAY6X1zTlWMy2bZ+ZW6wl/wLfn7EhF5H\nPWIcIgA3D/D0Nd/B/hWmrlcQTJtj3tM3M2Dlf4yYA/zyqPkD6DjW/Ia//YtJpJhzrfnsBv/FOGB1\nTG1CLlcB47TWt1i3rwMGOYdXlFJhQJ7Wulgp9WdgstZ61InarauQy9frkwn9ZhojLZschU9kn3G7\np03OEfj4Krj6PQhsZX5cox6FsA5m//E98MUNcO2X5gYAkHnA/FDLS4xw3/KruRD7Xg/lxUZAPrka\nkn5xnCcwGoY/CNnJrjn2AJe8aLxWMN5EeYljn8UT4qfA+g+rt7/PdPPDK8o23svV7xnxP7iq5vfc\n5VLY+QMMucNx4xl2v7mwqyOyG0z+GJITzMVgI6CVCR/t/sV0c/cvM57TkDvgdWsP84Ek41FVfs82\nRj1ibh5r/+e4UbbsZd7TFbPBv4XxxAKizIV8LNH1Zjn6Mfj1qartevpDSV7154yKN8IdMxDiJ8OP\n95sbwNRP4Ykg17oDZ5ibIpixne3fmte3Lob3LjbfTY+r4ANrmLDdcBgxEz65ygy8n4zK37czMQPM\nTXzCf+Dz6aYsrJPpKWz+3GwHtzU3zJB2kLnPlF3xNnS+BJ6LNttD7zU3072LHW27uZsxo5MRFW/a\ntr3vmxYYLziyq7kOSnJN+fiXoGU8/G+M49jz74GNn5jQhw1nO4PamB6vMx6+0PNqq0PR3dwk9i83\nn1FpofmNAXgGwJVvm7CpM636wk0/mZvjD3cbRwZlrtGYfuZ6/o+1pxU7DLqMNzcgMA7bTT+ZG+Yz\nLU0atc3OC582EYTT4EQhl9oI+hDgCa31RdbthwG01s/VUN8CZGitg6rbb6OuBP25+Tu4bM1UunXq\niNt51ntM+5Fn3G6DUFFufmTVdZ3LSkw87tcnzUU/5HZTfiwJXrd2gStfzFM/N/H9DyYYL2XjJ65t\ndhwDXoHGy0vf4cjWqYnWg4wonKi3YCM8znUw2MMPSvNd64R1Mh4gOETxZHgFmbDF8SRH2TUfwtzr\na3dscbbxZj0DzGswN5i+1zsuRBsdRpmu+/bvHGWB0aYXciZE9zfzJM6knbs2mpCcV6D5Xt4cUvtj\nQzsYL7cyrQfBxDccvycXm/vB4XU1tznmSUdP71TwDXftoZ53l4k3lxcbD373z6a87VA4sNz12Nhh\ncOMPpifnLMQdRjm86+rwskqT7fsfei+smmWuHZ9Qc/zWL82+6793pBd/d4fp6Qa1gXutPem8o/Bi\nJ/P60lfMjendi8z2P1JN7wrg5W7m++5yKUz5xPS+TvMRmWcaQ18LdFJKtcNksUwBplU6QZTW2tan\nmwDsOC1LT4Mdqbnc7JaHm39k4xVyG26WmmO47p7QaYz5cya8I0z/2ixn0OUSmDXY5NNHdIXO40yd\nv1k9mKRFjvx8MN3aLtYYYdZB8G9pLoycw3D9d/BSZ7Nv0F9NnP7Cp81Nx1nQ+99swhA2zrvLeMfH\nEiG8s/HEc4+YgaQvb3K13SbmYDx6Z1HuOsEc43wRh7Y3XevibIfAhHc24xI2qrtxgOl5bPjYxNoz\n9jkuZoBL/w1tBhubE951lF/4rBkbyU2FDyfCRc+a8NJnk83+cf+EvteZXpLFAxY8bMIQzj2V6ugy\n3nxfq2dBi57QcRSseNV4ueNfNmGAyG4mZOD8uQZGG6+41zUmbOYcE584y/RCDq4y3vO928zxW780\noaPEn0wIsLzEEaq4bTW8Mdi8vnkRRHQ2PREw5x/1qKm76vXqxdz5Rtp+pKO8smPx0D6HsK1739xQ\nSvLM76HgGAx/yLz/EQ+aXmdILPx4n7lp973B9FKUm+O30Gc6bPrckSLcZrDjXONfNoO/e34zN86B\nM0woJLCVCfXkphqBdvcx4dC9iyF+muldrXodLvi7GQfY+qX5XTjPFfGxJiPYwqbg+LzA9Pxs4amB\nMxzvGczvAxxjWPX0vOOTCrrWukwpdQewEJO2+K7WeptS6ikgQWv9PXCXUmoCUAZkADfWi7XVsCct\nlxCyTEphc8U2GARw3zbzg/SLqFrv9jVGmBMXGhFq5/RjtQ3yTf/KpGB6+BixSdtiLjLbj1hrE9IJ\njzMC4OHrEPQBt8DYp4z3ueULk6ETEWf+jjrd42+YZ7rKr/Qw25M/hk4XmfDKuveN1zb5I1j+b3MR\nu3mYC/rW3+CXx0y46KLnTNc7squ52YW2N+9nxEPWjKGtZsAV4Pa15mL28INR/zAXeMpmY9+BlQ5B\nuPTfZqA1Y58p87auqx/Q0nx2YAblwIjv4L+Y1xHWG99lr5oJZiMfNvWO74E+18K2b1wH0TqONiGl\nguNw3h3Gyz6yEWKHQr8bzKCiUibUlZtq4uu9p4PF6ZyV6TPd8drm/QW0MGMSRdnm+27R3dxsD6ww\n4yXhceaG7BcBrQc4jr97k7mevAKgZQ8zftKqrxHYnda04L8dcIxJ+Lcw4yNgvN/g1mZM4pIXjXA7\nT7Yb/FfzvzDLUTbkdiPObhaz3W2SEfSYATDBGp8vyjahs5EPm97mZa856vuEmP++4TDgZkfdi/8J\nMdU6sobpX5nrwfYb7XKJKY8ZYN577+mu9b2tnr3zgKuzaPuEmt/Zg3vAO9j12GJruO5UB9NPFa11\ng/z169dPnylFpWW6x8y5Wj8eqPXyV8+4PaES2Ye1PrDq5PU+ulLrhf9wPW7lLK0z9jnKysu0nneP\n1imbHWVLX9I64X3Xtvav0DrzgHm9cY75bv9427G/rETrA6tPblNJoTn206knr3sqFGabdr/4U+2P\n+flRc8yK/2i9+QutKyrq1qZT4eguY8uswad3/C9PaD1riGN753zH97z3d62P7zHf35rZJ2/rpa5a\nPxla/b7UbVoX59Xerrx0rQsyal//dFgz23x2H17uWv54oPlL3VbzsU9FmDoH/zhjMzCOdLW6etIY\nen1RFzH0lNVziVpgnZgz6a3mmY/dlKmoMCGMuHGnN6M2PdGMIXj61a1dR3easICHd+3qlxaaGO3g\n20y2REOitUmtbXseXPXuyevXJ0U5ZiC1NstlnAts/gK+vsX0Jq+d6yi3DXzfv8uR6FAZe51E03M6\nA840hn7O4rvmVcdGYFTDGSLUD25ujm7w6RARV3e2OBPZ5dTqe/jA8Afqx5ZTRSkzPuJ9wpyFs4Mt\npNVYcPc0/91qkE2fE9yYuk00g+v1PLmrUS8kkl/h6dgI7dBwhghCYyKic82epFAz5dZJQpYaBN3d\ns/pyMKmfDyTV22CojUYt6NllTh9sYHTDGSIIQtOnwygzkDzib6d+rLuXSbetZxp1yKWsyGmih6xa\nKAhCfeIbCnesrVredULVpQAaiEYr6KXlFQSUZYACul7W0OYIgtBcmfxRQ1tgp9G6tdmbfiBWpbKr\n3XSTxywIgtDMaZyCXpRN8AIz9b2iZf2uXiYIgtBYaJyCnrIJ95Icbix5CEvvKSevLwiC0AxonIJe\natbJzdZ+tAyq5eQOQRCEJk7jFPQyI+jKw5sAr0Y7risIglCnNGpB9/f3R9Vzor4gCEJjoVELuo/v\nCR4XJgiC0MxonIJujaH7+tbxokuCIAiNmMYp6LaQi98ZPgBaEAShCdEoBV2XmmfzBfhLyEUQBMFG\no0wRKSkuxKLdCAlo4LWlBUEQziEapaAXF+ZjwYMQvxMsVykIgtDMaJyCXlSAG56E+nk0tCmCIAjn\nDLWKoSulximldimlkpRSM09Q70qllFZKneDJrGdOaVEBxXgQ6udVn6cRBEFoVJxU0JVSFmAWcDHQ\nDZiqlOpWTb0A4G5gTV0bWZmykkKKtCehvhJyEQRBsFEbD30gkKS13qu1LgHmABOrqfc08E+gqA7t\nq5bykkLjofuLoAuCINiojaBHA4ectpOtZXaUUn2B1lrrH0/UkFJqhlIqQSmVkJ6efsrG2tClRZTg\niZ+n5bTbEARBaGqccR66UsoNeBm4/2R1tdaztdb9tdb9IyJO//l6urSIcouXrOMiCILgRG0E/TDQ\n2mk7xlpmIwDoASxRSu0HBgPf1+fAqCovosIiy+YKgiA4U5u0xbVAJ6VUO4yQTwGm2XZqrbOBcNu2\nUmoJ8IDWOqFuTXXgVl4M7iH11bwgNFlKS0tJTk6mqKjeh7qEM8Tb25uYmBg8PGqfnn1SQddalyml\n7gAWAhbgXa31NqXUpanuYAAAECRJREFUU0CC1vr707b4NLGUF4OPz9k+rSA0epKTkwkICCA2NlZC\nlucwWmuOHz9OcnIy7dq1q/VxtZpYpLWeD8yvVPZYDXVH1vrsp4mPLqTMIoIuCKdKUVGRiHkjQClF\nWFgYp5o80igX5/KhkFKLLJ0rCKeDiHnj4HS+p8Yn6BUV+FBMmbsszCUIguBM4xP00gLc0JS7i4cu\nCI2NrKws3njjjdM69pJLLiErK6uOLWpaND5BL8kHoMxDPHRBaGycSNDLyspOeOz8+fMJDg6uD7PO\nCK01FRUVDW0G0BhXWyzJA6BCPHRBOCOenLeN7Udy6rTNbq0Cefyy7jXunzlzJnv27KF3796MHTuW\n8ePH8+ijjxISEsLOnTtJTExk0qRJHDp0iKKiIu6++25mzJgBQGxsLAkJCeTl5XHxxRczdOhQVq5c\nSXR0NN999x0+lTLf5s2bxzPPPENJSQlhYWF88skntGjRgry8PO68804SEhJQSvH4449z5ZVXsmDB\nAv7+979TXl5OeHg4v/76K0888QT+/v488MADAPTo0YMffvgBgIsuuohBgwaxbt065s+fz/PPP8/a\ntWspLCzkqquu4sknnwRg7dq13H333eTn5+Pl5cWvv/7K+PHjee211+jduzcAQ4cOZdasWcTHx5/R\n59/oBL28KBcLUO4hTysShMbG888/z9atW9m4cSMAS5YsYf369WzdutWenvfuu+8SGhpKYWEhAwYM\n4MorryQsLMylnd27d/PZZ5/x9ttvc8011/DVV18xffp0lzpDhw5l9erVKKV45513eOGFF3jppZd4\n+umnCQoKYsuWLQBkZmaSnp7OrbfeytKlS2nXrh0ZGRknfS+7d+/mgw8+YPDgwQA8++yzhIaGUl5e\nzujRo9m8eTNdunRh8uTJfP755wwYMICcnBx8fHy4+eabef/993nllVdITEykqKjojMUcGqGglxXl\nYQG0hFwE4Yw4kSd9Nhk4cKBLrvVrr73GN998A8ChQ4fYvXt3FUFv166d3bvt168f+/fvr9JucnIy\nkydPJiUlhZKSEvs5Fi1axJw5c+z1QkJCmDdvHsOHD7fXCQ0NPandbdu2tYs5wNy5c5k9ezZlZWWk\npKSwfft2lFJERUUxYMAAAAIDAwG4+uqrefrpp/nXv/7Fu+++y4033njS89WGRhdDLy8yXUTtKSEX\nQWgK+Pk5ruUlS5awaNEiVq1axaZNm+jTp0+1s1q9vBzPQrBYLNXG3++8807uuOMOtmzZwn//+9/T\nmh3r7u7uEh93bsPZ7n379vHiiy/y66+/snnzZsaPH3/C8/n6+jJ27Fi+++475s6dy7XXXnvKtlVH\n4xP0QhNDx1NCLoLQ2AgICCA3N7fG/dnZ2YSEhODr68vOnTtZvXr1aZ8rOzub6GizMOwHH3xgLx87\ndiyzZs2yb2dmZjJ48GCWLl3Kvn37AOwhl9jYWNavXw/A+vXr7fsrk5OTg5+fH0FBQaSlpfHTTz8B\n0LlzZ1JSUli7di0Aubm59pvPLbfcwl133cWAAQMICambpUwanaBXFBtB1yLogtDoCAsL4/zzz6dH\njx48+OCDVfaPGzeOsrIyunbtysyZM11CGqfKE088wdVXX02/fv0ID7cvN8UjjzxCZmYmPXr0ID4+\nnsWLFxMREcHs2bO54ooriI+PZ/LkyQBceeWVZGRk0L17d15//XXi4uKqPVd8fDx9+vShS5cuTJs2\njfPPPx8AT09PPv/8c+68807i4+MZO3as3XPv168fgYGB3HTTTaf9HiujtNZ11tip0L9/f52QcOrr\nd2X+9iohSx/j2wtXMOm8HvVgmSA0XXbs2EHXrl0b2gwBOHLkCCNHjmTnzp3/3979x0ZRpgEc/z5t\nF3sVPMCKIK0HelwqP7YtNoJgtEeuR/GwFEOvAhFDVFIFlXDmUuVCPAIJkMYfEOyhOSFFuJ70wCLQ\ncCA15GKCtgilwoH1UkOLpT+sYNOCpbz3x043C27L9seyzuzzSTad9513Z99nOzxM35l5h4gI/8fW\n/n5fIlJujPE7m63tjtDbowZy+mocEdE6hq6UsqeCggImTZrE6tWru0zmvWG7hN78mz8y/cd1RLl0\nPnSllD0tWLCAs2fPkpWV1a/btV1Cb+/wnHF2Rdqu60opFVS2y4o/ehO6zhinlFK+bJfQ26/oEbpS\nSvlju6zY3uG5KkcTulJKXct2WbFdh1yUCisDB3ruOTl37hxz5szx2yY1NZXeXAbtNAEldBFJF5HT\nIlIlIrl+1ueIyAkROSYi/xGRsf3fVQ89KapUeLrrrrsoKioKdTf8utHUvzfLDSfnEpFIYCOQBtQA\nn4vIbmPMSZ9m240xf7PaZwCvA+lB6K93yGVAlCZ0pfqkJBfqTvTvNodPgBlrulydm5tLfHw8ixcv\nBvBOT5uTk8OsWbNobm6mvb2dVatWMWvWrGveW11dzcyZM6msrKStrY2FCxdy/PhxEhISaGtr8/t5\nK1eu5KOPPqKtrY0pU6awadMmRISqqipycnJoaGggMjKSHTt2cO+997J27Vref/99IiIimDFjBmvW\nrCE1NZW8vDxSUlJobGwkJSWF6upqtmzZws6dO2lpaaGjo4O9e/d2GUNBQQF5eXmICG63m7fffhu3\n282ZM2dwuVxcvHiRxMREb7m3Aplt8QGgyhjzPwARKQRmAd6EbozxnVT5ViBot5/qEbpS9pWdnc3S\npUu9Cf2DDz5g//79REdHs2vXLm677TYaGxuZPHkyGRkZXT5XMz8/n5iYGE6dOkVFRQUTJ070227J\nkiWsWOF5nv2TTz7Jnj17eOyxx5g/fz65ubnMnj2bS5cucfXqVUpKSiguLubIkSPExMQENIXu0aNH\nqaioYOjQoVy5csVvDCdPnmTVqlV8+umnxMbG8t133zFo0CBSU1PZu3cvmZmZFBYW8vjjj/cpmUNg\nCX0kcNanXANMur6RiCwGlgEDgGn+NiQii4BFAHfffXdP+wroZYtK9ZtujqSDJTk5mfr6es6dO0dD\nQwNDhgwhPj6e9vZ2Xn31VQ4fPkxERAS1tbWcP3+e4cOH+93O4cOHefHFFwFwu9243W6/7UpLS1m3\nbh2tra3eOVlSU1Opra1l9uzZAERHe25SPHjwIAsXLiQmxjM1dyBT6KalpXnbGWP8xnDo0CGysrK8\n88l0tn/mmWdYt24dmZmZbN68mXfffTfQr7FL/TYfujFmI7BRROYBfwGe8tPmHeAd8Mzl0pvP6TxC\nH6BH6ErZUlZWFkVFRdTV1Xknwdq2bRsNDQ2Ul5fjcrkYNWpUr6a79XXp0iWef/55ysrKiI+P57XX\nXuvzFLrXv993Ct2exjB16lSqq6v55JNP6OjoYPz4vs9NFUhWrAXifcpxVl1XCoHMvnSqO3odulL2\nlp2dTWFhIUVFRd5b3y9cuMCwYcNwuVyUlpbyzTffdLuNhx9+mO3btwNQWVlJRUXFT9p0JtPY2Fha\nWlq8J1QHDRpEXFwcH374IQCXL1+mtbWVtLQ0Nm/eTGtrK3DtFLrl5eUA3Z6U7SqGadOmsWPHDpqa\nmq7ZLnimAJg3b16/zbgYSFb8HBgjIqNFZADwBLDbt4GIjPEp/gH4ql9650fnSdEoHXJRypbGjRvH\nDz/8wMiRIxkxYgQA8+fPp6ysjAkTJlBQUEBCQkK323juuedoaWnhvvvuY8WKFdx///0/aTN48GCe\nffZZxo8fz/Tp071PDQLYunUr69evx+12M2XKFOrq6khPTycjI4OUlBSSkpLIy8sD4OWXXyY/P5/k\n5GQaGxu77FNXMYwbN47ly5fzyCOPkJiYyLJly655T3NzM3Pnzg38C+xGQNPnisijwJtAJPCeMWa1\niKwEyowxu0XkLeB3QDvQDCwxxnzZ3TZ7O33ugZPn2fVFDW9kJ3FLVGSP369UONPpc39eioqKKC4u\nZuvWrX7X93T63IDG0I0x+4B919Wt8Fl+KZDt9Ie0sXeSNvbOm/VxSikVFC+88AIlJSXs27fvxo0D\nZLuHRCullBNs2LCh37epZxaVCjOhekqZ6pne/J40oSsVRqKjo2lqatKk/jNnjKGpqcl7jXygdMhF\nqTASFxdHTU0NDQ0Noe6KuoHo6Gji4uJ69B5N6EqFEZfLxejRo0PdDRUkOuSilFIOoQldKaUcQhO6\nUko5REB3igblg0UagO4nbOhaLND1PbjOpDGHB405PPQl5l8ZY+7wtyJkCb0vRKSsq1tfnUpjDg8a\nc3gIVsw65KKUUg6hCV0ppRzCrgn9nVB3IAQ05vCgMYeHoMRsyzF0pZRSP2XXI3SllFLX0YSulFIO\nYbuELiLpInJaRKpEJDfU/ekvIvKeiNSLSKVP3VAROSAiX1k/h1j1IiLrre+gQkQmhq7nvSci8SJS\nKiInReRLEXnJqnds3CISLSKfichxK+a/WvWjReSIFds/rcc9IiK3WOUqa/2oUPa/t0QkUkS+EJE9\nVtnR8QKISLWInBCRYyJSZtUFdd+2VUIXkUhgIzADGAvMFZGxoe1Vv9kCpF9Xlwt8bIwZA3xslcET\n/xjrtQjIv0l97G9XgD8ZY8YCk4HF1u/TyXFfBqYZYxKBJCBdRCYDa4E3jDG/xvMYx6et9k8DzVb9\nG1Y7O3oJOOVTdnq8nX5rjEnyueY8uPu2McY2L+BBYL9P+RXglVD3qx/jGwVU+pRPAyOs5RHAaWt5\nEzDXXzs7v4BiIC1c4gZigKPAJDx3DUZZ9d79HNgPPGgtR1ntJNR972GccVbymgbsAcTJ8frEXQ3E\nXlcX1H3bVkfowEjgrE+5xqpzqjuNMd9ay3VA58NUHfc9WH9aJwNHcHjc1vDDMaAeOAB8DXxvjLli\nNfGNyxuztf4CcPvN7XGfvQn8GbhqlW/H2fF2MsC/RaRcRBZZdUHdt3U+dJswxhgRceQ1piIyEPgX\nsNQYc1FEvOucGLcxpgNIEpHBwC4gIcRdChoRmQnUG2PKRSQ11P25yR4yxtSKyDDggIj813dlMPZt\nux2h1wLxPuU4q86pzovICADrZ71V75jvQURceJL5NmPMTqva8XEDGGO+B0rxDDkMFpHOAyzfuLwx\nW+t/CTTd5K72xVQgQ0SqgUI8wy5v4dx4vYwxtdbPejz/cT9AkPdtuyX0z4Ex1hnyAcATwO4Q9ymY\ndgNPWctP4Rlj7qxfYJ0Znwxc8PkzzjbEcyj+d+CUMeZ1n1WOjVtE7rCOzBGRX+A5Z3AKT2KfYzW7\nPubO72IOcMhYg6x2YIx5xRgTZ4wZheff6yFjzHwcGm8nEblVRAZ1LgO/ByoJ9r4d6hMHvTjR8Chw\nBs+44/JQ96cf4/oH8C3Qjmf87Gk8Y4cfA18BB4GhVlvBc7XP18AJICXU/e9lzA/hGWesAI5Zr0ed\nHDfgBr6wYq4EVlj19wCfAVXADuAWqz7aKldZ6+8JdQx9iD0V2BMO8VrxHbdeX3bmqmDv23rrv1JK\nOYTdhlyUUkp1QRO6Uko5hCZ0pZRyCE3oSinlEJrQlVLKITShK6WUQ2hCV0oph/g/9QhzMcMok+8A\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 以視覺畫方式檢視訓練過程\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mL9Bj66TI6eb"
   },
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cg6h1GCmJpfZ"
   },
   "outputs": [],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtTXcjEwJvrf"
   },
   "outputs": [],
   "source": [
    "# 將 X 與 Y 獨立放進變數\n",
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "# 資料前處理 - 標準化\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "x_test = x_test.reshape((len(x_test), -1))\n",
    "\n",
    "# 將目標轉為 one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1574578608104,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "H_rSobD9IYX4",
    "outputId": "aee6a1a2-2c2f-4de9-f17c-48dc3bc9de12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,746,506\n",
      "Trainable params: 1,746,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 850448,
     "status": "ok",
     "timestamp": 1574579490517,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "uaqZYNW7Mbvj",
    "outputId": "47b672c5-087e-4ff5-b0fd-b7ab1522cffb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "50000/50000 [==============================] - 2s 41us/step - loss: 0.0059 - acc: 0.9996 - val_loss: 4.7801 - val_acc: 0.4978\n",
      "Epoch 2/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 4.8077 - val_acc: 0.4991\n",
      "Epoch 3/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 4.8352 - val_acc: 0.4994\n",
      "Epoch 4/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0035 - acc: 0.9999 - val_loss: 4.8640 - val_acc: 0.5010\n",
      "Epoch 5/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 4.8850 - val_acc: 0.5018\n",
      "Epoch 6/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 4.9088 - val_acc: 0.5022\n",
      "Epoch 7/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 4.9288 - val_acc: 0.5027\n",
      "Epoch 8/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 4.9448 - val_acc: 0.5029\n",
      "Epoch 9/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 4.9618 - val_acc: 0.5015\n",
      "Epoch 10/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 4.9777 - val_acc: 0.5028\n",
      "Epoch 11/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 4.9930 - val_acc: 0.5022\n",
      "Epoch 12/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 5.0092 - val_acc: 0.5031\n",
      "Epoch 13/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 5.0228 - val_acc: 0.5032\n",
      "Epoch 14/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 5.0356 - val_acc: 0.5033\n",
      "Epoch 15/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 5.0474 - val_acc: 0.5020\n",
      "Epoch 16/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 5.0605 - val_acc: 0.5034\n",
      "Epoch 17/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 5.0733 - val_acc: 0.5039\n",
      "Epoch 18/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 5.0830 - val_acc: 0.5026\n",
      "Epoch 19/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 5.0942 - val_acc: 0.5032\n",
      "Epoch 20/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 5.1053 - val_acc: 0.5034\n",
      "Epoch 21/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 5.1158 - val_acc: 0.5030\n",
      "Epoch 22/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 5.1243 - val_acc: 0.5029\n",
      "Epoch 23/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 5.1330 - val_acc: 0.5025\n",
      "Epoch 24/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 5.1425 - val_acc: 0.5034\n",
      "Epoch 25/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 5.1516 - val_acc: 0.5035\n",
      "Epoch 26/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 5.1602 - val_acc: 0.5037\n",
      "Epoch 27/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 5.1690 - val_acc: 0.5028\n",
      "Epoch 28/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 5.1759 - val_acc: 0.5023\n",
      "Epoch 29/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 5.1835 - val_acc: 0.5026\n",
      "Epoch 30/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 5.1923 - val_acc: 0.5030\n",
      "Epoch 31/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 5.1995 - val_acc: 0.5030\n",
      "Epoch 32/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.2073 - val_acc: 0.5030\n",
      "Epoch 33/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.2148 - val_acc: 0.5030\n",
      "Epoch 34/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.2211 - val_acc: 0.5027\n",
      "Epoch 35/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.2285 - val_acc: 0.5029\n",
      "Epoch 36/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.2351 - val_acc: 0.5027\n",
      "Epoch 37/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.2422 - val_acc: 0.5033\n",
      "Epoch 38/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.2478 - val_acc: 0.5030\n",
      "Epoch 39/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.2538 - val_acc: 0.5032\n",
      "Epoch 40/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.2603 - val_acc: 0.5026\n",
      "Epoch 41/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.2668 - val_acc: 0.5032\n",
      "Epoch 42/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 5.2731 - val_acc: 0.5037\n",
      "Epoch 43/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 5.2796 - val_acc: 0.5034\n",
      "Epoch 44/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 5.2843 - val_acc: 0.5020\n",
      "Epoch 45/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 5.2903 - val_acc: 0.5028\n",
      "Epoch 46/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 5.2947 - val_acc: 0.5028\n",
      "Epoch 47/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 5.3008 - val_acc: 0.5026\n",
      "Epoch 48/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 5.3059 - val_acc: 0.5019\n",
      "Epoch 49/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 5.3115 - val_acc: 0.5024\n",
      "Epoch 50/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 5.3163 - val_acc: 0.5029\n",
      "Epoch 51/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 9.9142e-04 - acc: 1.0000 - val_loss: 5.3190 - val_acc: 0.5021\n",
      "Epoch 52/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 9.8386e-04 - acc: 1.0000 - val_loss: 5.3256 - val_acc: 0.5029\n",
      "Epoch 53/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 9.6542e-04 - acc: 1.0000 - val_loss: 5.3310 - val_acc: 0.5025\n",
      "Epoch 54/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 9.5323e-04 - acc: 1.0000 - val_loss: 5.3356 - val_acc: 0.5028\n",
      "Epoch 55/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 9.4077e-04 - acc: 1.0000 - val_loss: 5.3405 - val_acc: 0.5033\n",
      "Epoch 56/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 9.2836e-04 - acc: 1.0000 - val_loss: 5.3453 - val_acc: 0.5028\n",
      "Epoch 57/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 9.1631e-04 - acc: 1.0000 - val_loss: 5.3501 - val_acc: 0.5027\n",
      "Epoch 58/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 9.0288e-04 - acc: 1.0000 - val_loss: 5.3549 - val_acc: 0.5035\n",
      "Epoch 59/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 8.9423e-04 - acc: 1.0000 - val_loss: 5.3588 - val_acc: 0.5026\n",
      "Epoch 60/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 8.8176e-04 - acc: 1.0000 - val_loss: 5.3634 - val_acc: 0.5025\n",
      "Epoch 61/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 8.7133e-04 - acc: 1.0000 - val_loss: 5.3677 - val_acc: 0.5031\n",
      "Epoch 62/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 8.6046e-04 - acc: 1.0000 - val_loss: 5.3724 - val_acc: 0.5026\n",
      "Epoch 63/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 8.5035e-04 - acc: 1.0000 - val_loss: 5.3765 - val_acc: 0.5029\n",
      "Epoch 64/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 8.4059e-04 - acc: 1.0000 - val_loss: 5.3793 - val_acc: 0.5031\n",
      "Epoch 65/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 8.3102e-04 - acc: 1.0000 - val_loss: 5.3839 - val_acc: 0.5033\n",
      "Epoch 66/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 8.2189e-04 - acc: 1.0000 - val_loss: 5.3878 - val_acc: 0.5033\n",
      "Epoch 67/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 8.1287e-04 - acc: 1.0000 - val_loss: 5.3919 - val_acc: 0.5029\n",
      "Epoch 68/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 8.0094e-04 - acc: 1.0000 - val_loss: 5.3967 - val_acc: 0.5033\n",
      "Epoch 69/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 7.9440e-04 - acc: 1.0000 - val_loss: 5.3993 - val_acc: 0.5025\n",
      "Epoch 70/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 7.8534e-04 - acc: 1.0000 - val_loss: 5.4039 - val_acc: 0.5037\n",
      "Epoch 71/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 7.7536e-04 - acc: 1.0000 - val_loss: 5.4078 - val_acc: 0.5035\n",
      "Epoch 72/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 7.6779e-04 - acc: 1.0000 - val_loss: 5.4116 - val_acc: 0.5032\n",
      "Epoch 73/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 7.5957e-04 - acc: 1.0000 - val_loss: 5.4155 - val_acc: 0.5029\n",
      "Epoch 74/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 7.5162e-04 - acc: 1.0000 - val_loss: 5.4200 - val_acc: 0.5031\n",
      "Epoch 75/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 7.4420e-04 - acc: 1.0000 - val_loss: 5.4224 - val_acc: 0.5036\n",
      "Epoch 76/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 7.3561e-04 - acc: 1.0000 - val_loss: 5.4263 - val_acc: 0.5037\n",
      "Epoch 77/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 7.2783e-04 - acc: 1.0000 - val_loss: 5.4295 - val_acc: 0.5026\n",
      "Epoch 78/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 7.2028e-04 - acc: 1.0000 - val_loss: 5.4337 - val_acc: 0.5041\n",
      "Epoch 79/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 7.1358e-04 - acc: 1.0000 - val_loss: 5.4362 - val_acc: 0.5031\n",
      "Epoch 80/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 7.0724e-04 - acc: 1.0000 - val_loss: 5.4393 - val_acc: 0.5028\n",
      "Epoch 81/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 6.9990e-04 - acc: 1.0000 - val_loss: 5.4432 - val_acc: 0.5036\n",
      "Epoch 82/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 6.9240e-04 - acc: 1.0000 - val_loss: 5.4461 - val_acc: 0.5032\n",
      "Epoch 83/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 6.8619e-04 - acc: 1.0000 - val_loss: 5.4497 - val_acc: 0.5035\n",
      "Epoch 84/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 6.7943e-04 - acc: 1.0000 - val_loss: 5.4537 - val_acc: 0.5032\n",
      "Epoch 85/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 6.7296e-04 - acc: 1.0000 - val_loss: 5.4557 - val_acc: 0.5033\n",
      "Epoch 86/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 6.6635e-04 - acc: 1.0000 - val_loss: 5.4588 - val_acc: 0.5033\n",
      "Epoch 87/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 6.5940e-04 - acc: 1.0000 - val_loss: 5.4622 - val_acc: 0.5035\n",
      "Epoch 88/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 6.5464e-04 - acc: 1.0000 - val_loss: 5.4655 - val_acc: 0.5030\n",
      "Epoch 89/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 6.4860e-04 - acc: 1.0000 - val_loss: 5.4693 - val_acc: 0.5029\n",
      "Epoch 90/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 6.4294e-04 - acc: 1.0000 - val_loss: 5.4715 - val_acc: 0.5033\n",
      "Epoch 91/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 6.3684e-04 - acc: 1.0000 - val_loss: 5.4746 - val_acc: 0.5030\n",
      "Epoch 92/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 6.3083e-04 - acc: 1.0000 - val_loss: 5.4777 - val_acc: 0.5027\n",
      "Epoch 93/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 6.2515e-04 - acc: 1.0000 - val_loss: 5.4807 - val_acc: 0.5036\n",
      "Epoch 94/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 6.1941e-04 - acc: 1.0000 - val_loss: 5.4839 - val_acc: 0.5035\n",
      "Epoch 95/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 6.1455e-04 - acc: 1.0000 - val_loss: 5.4864 - val_acc: 0.5029\n",
      "Epoch 96/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 6.0873e-04 - acc: 1.0000 - val_loss: 5.4896 - val_acc: 0.5033\n",
      "Epoch 97/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 6.0415e-04 - acc: 1.0000 - val_loss: 5.4917 - val_acc: 0.5034\n",
      "Epoch 98/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 5.9867e-04 - acc: 1.0000 - val_loss: 5.4949 - val_acc: 0.5034\n",
      "Epoch 99/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 5.9302e-04 - acc: 1.0000 - val_loss: 5.4976 - val_acc: 0.5029\n",
      "Epoch 100/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 5.8867e-04 - acc: 1.0000 - val_loss: 5.5003 - val_acc: 0.5025\n",
      "Epoch 101/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 5.8367e-04 - acc: 1.0000 - val_loss: 5.5036 - val_acc: 0.5035\n",
      "Epoch 102/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 5.7897e-04 - acc: 1.0000 - val_loss: 5.5058 - val_acc: 0.5036\n",
      "Epoch 103/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 5.7417e-04 - acc: 1.0000 - val_loss: 5.5086 - val_acc: 0.5033\n",
      "Epoch 104/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 5.6936e-04 - acc: 1.0000 - val_loss: 5.5115 - val_acc: 0.5034\n",
      "Epoch 105/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 5.6490e-04 - acc: 1.0000 - val_loss: 5.5140 - val_acc: 0.5036\n",
      "Epoch 106/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 5.6036e-04 - acc: 1.0000 - val_loss: 5.5164 - val_acc: 0.5039\n",
      "Epoch 107/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 5.5594e-04 - acc: 1.0000 - val_loss: 5.5190 - val_acc: 0.5035\n",
      "Epoch 108/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 5.5150e-04 - acc: 1.0000 - val_loss: 5.5213 - val_acc: 0.5035\n",
      "Epoch 109/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 5.4729e-04 - acc: 1.0000 - val_loss: 5.5240 - val_acc: 0.5031\n",
      "Epoch 110/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 5.4246e-04 - acc: 1.0000 - val_loss: 5.5264 - val_acc: 0.5033\n",
      "Epoch 111/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 5.3897e-04 - acc: 1.0000 - val_loss: 5.5292 - val_acc: 0.5034\n",
      "Epoch 112/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 5.3472e-04 - acc: 1.0000 - val_loss: 5.5315 - val_acc: 0.5034\n",
      "Epoch 113/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 5.3029e-04 - acc: 1.0000 - val_loss: 5.5343 - val_acc: 0.5032\n",
      "Epoch 114/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 5.2682e-04 - acc: 1.0000 - val_loss: 5.5361 - val_acc: 0.5034\n",
      "Epoch 115/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 5.2271e-04 - acc: 1.0000 - val_loss: 5.5388 - val_acc: 0.5033\n",
      "Epoch 116/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 5.1882e-04 - acc: 1.0000 - val_loss: 5.5412 - val_acc: 0.5030\n",
      "Epoch 117/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 5.1459e-04 - acc: 1.0000 - val_loss: 5.5433 - val_acc: 0.5033\n",
      "Epoch 118/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 5.1127e-04 - acc: 1.0000 - val_loss: 5.5454 - val_acc: 0.5035\n",
      "Epoch 119/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 5.0751e-04 - acc: 1.0000 - val_loss: 5.5482 - val_acc: 0.5036\n",
      "Epoch 120/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 5.0400e-04 - acc: 1.0000 - val_loss: 5.5507 - val_acc: 0.5036\n",
      "Epoch 121/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 5.0002e-04 - acc: 1.0000 - val_loss: 5.5526 - val_acc: 0.5035\n",
      "Epoch 122/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 4.9651e-04 - acc: 1.0000 - val_loss: 5.5544 - val_acc: 0.5033\n",
      "Epoch 123/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.9278e-04 - acc: 1.0000 - val_loss: 5.5570 - val_acc: 0.5031\n",
      "Epoch 124/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 4.8901e-04 - acc: 1.0000 - val_loss: 5.5591 - val_acc: 0.5032\n",
      "Epoch 125/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.8637e-04 - acc: 1.0000 - val_loss: 5.5613 - val_acc: 0.5035\n",
      "Epoch 126/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.8270e-04 - acc: 1.0000 - val_loss: 5.5637 - val_acc: 0.5034\n",
      "Epoch 127/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.7904e-04 - acc: 1.0000 - val_loss: 5.5658 - val_acc: 0.5036\n",
      "Epoch 128/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.7634e-04 - acc: 1.0000 - val_loss: 5.5675 - val_acc: 0.5036\n",
      "Epoch 129/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.7245e-04 - acc: 1.0000 - val_loss: 5.5698 - val_acc: 0.5033\n",
      "Epoch 130/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 4.6952e-04 - acc: 1.0000 - val_loss: 5.5717 - val_acc: 0.5036\n",
      "Epoch 131/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 4.6672e-04 - acc: 1.0000 - val_loss: 5.5740 - val_acc: 0.5034\n",
      "Epoch 132/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.6319e-04 - acc: 1.0000 - val_loss: 5.5762 - val_acc: 0.5033\n",
      "Epoch 133/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 4.6039e-04 - acc: 1.0000 - val_loss: 5.5779 - val_acc: 0.5035\n",
      "Epoch 134/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.5690e-04 - acc: 1.0000 - val_loss: 5.5800 - val_acc: 0.5034\n",
      "Epoch 135/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 4.5401e-04 - acc: 1.0000 - val_loss: 5.5818 - val_acc: 0.5036\n",
      "Epoch 136/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.5091e-04 - acc: 1.0000 - val_loss: 5.5842 - val_acc: 0.5036\n",
      "Epoch 137/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.4849e-04 - acc: 1.0000 - val_loss: 5.5859 - val_acc: 0.5037\n",
      "Epoch 138/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.4527e-04 - acc: 1.0000 - val_loss: 5.5879 - val_acc: 0.5036\n",
      "Epoch 139/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.4250e-04 - acc: 1.0000 - val_loss: 5.5897 - val_acc: 0.5036\n",
      "Epoch 140/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.3973e-04 - acc: 1.0000 - val_loss: 5.5920 - val_acc: 0.5034\n",
      "Epoch 141/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.3705e-04 - acc: 1.0000 - val_loss: 5.5937 - val_acc: 0.5036\n",
      "Epoch 142/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 4.3414e-04 - acc: 1.0000 - val_loss: 5.5953 - val_acc: 0.5039\n",
      "Epoch 143/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 4.3163e-04 - acc: 1.0000 - val_loss: 5.5975 - val_acc: 0.5037\n",
      "Epoch 144/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.2869e-04 - acc: 1.0000 - val_loss: 5.5992 - val_acc: 0.5037\n",
      "Epoch 145/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.2608e-04 - acc: 1.0000 - val_loss: 5.6014 - val_acc: 0.5036\n",
      "Epoch 146/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 4.2339e-04 - acc: 1.0000 - val_loss: 5.6032 - val_acc: 0.5033\n",
      "Epoch 147/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.2081e-04 - acc: 1.0000 - val_loss: 5.6052 - val_acc: 0.5034\n",
      "Epoch 148/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.1813e-04 - acc: 1.0000 - val_loss: 5.6068 - val_acc: 0.5037\n",
      "Epoch 149/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.1531e-04 - acc: 1.0000 - val_loss: 5.6088 - val_acc: 0.5038\n",
      "Epoch 150/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.1340e-04 - acc: 1.0000 - val_loss: 5.6102 - val_acc: 0.5041\n",
      "Epoch 151/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.1080e-04 - acc: 1.0000 - val_loss: 5.6122 - val_acc: 0.5038\n",
      "Epoch 152/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 4.0847e-04 - acc: 1.0000 - val_loss: 5.6138 - val_acc: 0.5042\n",
      "Epoch 153/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.0607e-04 - acc: 1.0000 - val_loss: 5.6155 - val_acc: 0.5039\n",
      "Epoch 154/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 4.0369e-04 - acc: 1.0000 - val_loss: 5.6172 - val_acc: 0.5037\n",
      "Epoch 155/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 4.0136e-04 - acc: 1.0000 - val_loss: 5.6190 - val_acc: 0.5036\n",
      "Epoch 156/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.9863e-04 - acc: 1.0000 - val_loss: 5.6211 - val_acc: 0.5035\n",
      "Epoch 157/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.9682e-04 - acc: 1.0000 - val_loss: 5.6227 - val_acc: 0.5034\n",
      "Epoch 158/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 3.9411e-04 - acc: 1.0000 - val_loss: 5.6244 - val_acc: 0.5036\n",
      "Epoch 159/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 3.9201e-04 - acc: 1.0000 - val_loss: 5.6258 - val_acc: 0.5035\n",
      "Epoch 160/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.8996e-04 - acc: 1.0000 - val_loss: 5.6275 - val_acc: 0.5035\n",
      "Epoch 161/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.8765e-04 - acc: 1.0000 - val_loss: 5.6296 - val_acc: 0.5038\n",
      "Epoch 162/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.8528e-04 - acc: 1.0000 - val_loss: 5.6311 - val_acc: 0.5035\n",
      "Epoch 163/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 3.8320e-04 - acc: 1.0000 - val_loss: 5.6326 - val_acc: 0.5039\n",
      "Epoch 164/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 3.8105e-04 - acc: 1.0000 - val_loss: 5.6342 - val_acc: 0.5035\n",
      "Epoch 165/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.7889e-04 - acc: 1.0000 - val_loss: 5.6361 - val_acc: 0.5035\n",
      "Epoch 166/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.7693e-04 - acc: 1.0000 - val_loss: 5.6375 - val_acc: 0.5039\n",
      "Epoch 167/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.7492e-04 - acc: 1.0000 - val_loss: 5.6392 - val_acc: 0.5035\n",
      "Epoch 168/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.7277e-04 - acc: 1.0000 - val_loss: 5.6407 - val_acc: 0.5035\n",
      "Epoch 169/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.7079e-04 - acc: 1.0000 - val_loss: 5.6424 - val_acc: 0.5037\n",
      "Epoch 170/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.6873e-04 - acc: 1.0000 - val_loss: 5.6440 - val_acc: 0.5038\n",
      "Epoch 171/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 3.6677e-04 - acc: 1.0000 - val_loss: 5.6458 - val_acc: 0.5035\n",
      "Epoch 172/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.6491e-04 - acc: 1.0000 - val_loss: 5.6472 - val_acc: 0.5039\n",
      "Epoch 173/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.6290e-04 - acc: 1.0000 - val_loss: 5.6489 - val_acc: 0.5038\n",
      "Epoch 174/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 3.6091e-04 - acc: 1.0000 - val_loss: 5.6500 - val_acc: 0.5038\n",
      "Epoch 175/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.5868e-04 - acc: 1.0000 - val_loss: 5.6521 - val_acc: 0.5036\n",
      "Epoch 176/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.5735e-04 - acc: 1.0000 - val_loss: 5.6535 - val_acc: 0.5035\n",
      "Epoch 177/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 3.5515e-04 - acc: 1.0000 - val_loss: 5.6547 - val_acc: 0.5039\n",
      "Epoch 178/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.5343e-04 - acc: 1.0000 - val_loss: 5.6563 - val_acc: 0.5039\n",
      "Epoch 179/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.5157e-04 - acc: 1.0000 - val_loss: 5.6579 - val_acc: 0.5034\n",
      "Epoch 180/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.4978e-04 - acc: 1.0000 - val_loss: 5.6593 - val_acc: 0.5039\n",
      "Epoch 181/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.4795e-04 - acc: 1.0000 - val_loss: 5.6607 - val_acc: 0.5037\n",
      "Epoch 182/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.4624e-04 - acc: 1.0000 - val_loss: 5.6621 - val_acc: 0.5037\n",
      "Epoch 183/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 3.4450e-04 - acc: 1.0000 - val_loss: 5.6637 - val_acc: 0.5036\n",
      "Epoch 184/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.4272e-04 - acc: 1.0000 - val_loss: 5.6655 - val_acc: 0.5035\n",
      "Epoch 185/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.4102e-04 - acc: 1.0000 - val_loss: 5.6667 - val_acc: 0.5037\n",
      "Epoch 186/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.3927e-04 - acc: 1.0000 - val_loss: 5.6683 - val_acc: 0.5035\n",
      "Epoch 187/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.3759e-04 - acc: 1.0000 - val_loss: 5.6697 - val_acc: 0.5033\n",
      "Epoch 188/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.3595e-04 - acc: 1.0000 - val_loss: 5.6710 - val_acc: 0.5037\n",
      "Epoch 189/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 3.3423e-04 - acc: 1.0000 - val_loss: 5.6724 - val_acc: 0.5035\n",
      "Epoch 190/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.3254e-04 - acc: 1.0000 - val_loss: 5.6740 - val_acc: 0.5037\n",
      "Epoch 191/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.3091e-04 - acc: 1.0000 - val_loss: 5.6751 - val_acc: 0.5034\n",
      "Epoch 192/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.2916e-04 - acc: 1.0000 - val_loss: 5.6766 - val_acc: 0.5034\n",
      "Epoch 193/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.2768e-04 - acc: 1.0000 - val_loss: 5.6781 - val_acc: 0.5033\n",
      "Epoch 194/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.2627e-04 - acc: 1.0000 - val_loss: 5.6793 - val_acc: 0.5036\n",
      "Epoch 195/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.2439e-04 - acc: 1.0000 - val_loss: 5.6806 - val_acc: 0.5033\n",
      "Epoch 196/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 3.2294e-04 - acc: 1.0000 - val_loss: 5.6824 - val_acc: 0.5033\n",
      "Epoch 197/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.2167e-04 - acc: 1.0000 - val_loss: 5.6834 - val_acc: 0.5031\n",
      "Epoch 198/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 3.2000e-04 - acc: 1.0000 - val_loss: 5.6847 - val_acc: 0.5033\n",
      "Epoch 199/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 3.1838e-04 - acc: 1.0000 - val_loss: 5.6860 - val_acc: 0.5034\n",
      "Epoch 200/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.1685e-04 - acc: 1.0000 - val_loss: 5.6873 - val_acc: 0.5032\n",
      "Epoch 201/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.1533e-04 - acc: 1.0000 - val_loss: 5.6884 - val_acc: 0.5035\n",
      "Epoch 202/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.1381e-04 - acc: 1.0000 - val_loss: 5.6899 - val_acc: 0.5036\n",
      "Epoch 203/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 3.1250e-04 - acc: 1.0000 - val_loss: 5.6912 - val_acc: 0.5035\n",
      "Epoch 204/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 3.1103e-04 - acc: 1.0000 - val_loss: 5.6927 - val_acc: 0.5033\n",
      "Epoch 205/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 3.0953e-04 - acc: 1.0000 - val_loss: 5.6940 - val_acc: 0.5033\n",
      "Epoch 206/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.0809e-04 - acc: 1.0000 - val_loss: 5.6953 - val_acc: 0.5031\n",
      "Epoch 207/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 3.0660e-04 - acc: 1.0000 - val_loss: 5.6967 - val_acc: 0.5031\n",
      "Epoch 208/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 3.0542e-04 - acc: 1.0000 - val_loss: 5.6976 - val_acc: 0.5033\n",
      "Epoch 209/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.0394e-04 - acc: 1.0000 - val_loss: 5.6990 - val_acc: 0.5032\n",
      "Epoch 210/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 3.0245e-04 - acc: 1.0000 - val_loss: 5.7001 - val_acc: 0.5034\n",
      "Epoch 211/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 3.0129e-04 - acc: 1.0000 - val_loss: 5.7014 - val_acc: 0.5032\n",
      "Epoch 212/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.9988e-04 - acc: 1.0000 - val_loss: 5.7027 - val_acc: 0.5032\n",
      "Epoch 213/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.9854e-04 - acc: 1.0000 - val_loss: 5.7039 - val_acc: 0.5033\n",
      "Epoch 214/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.9716e-04 - acc: 1.0000 - val_loss: 5.7050 - val_acc: 0.5032\n",
      "Epoch 215/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.9583e-04 - acc: 1.0000 - val_loss: 5.7063 - val_acc: 0.5034\n",
      "Epoch 216/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.9461e-04 - acc: 1.0000 - val_loss: 5.7075 - val_acc: 0.5032\n",
      "Epoch 217/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.9322e-04 - acc: 1.0000 - val_loss: 5.7089 - val_acc: 0.5030\n",
      "Epoch 218/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.9194e-04 - acc: 1.0000 - val_loss: 5.7099 - val_acc: 0.5034\n",
      "Epoch 219/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.9071e-04 - acc: 1.0000 - val_loss: 5.7113 - val_acc: 0.5035\n",
      "Epoch 220/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.8939e-04 - acc: 1.0000 - val_loss: 5.7124 - val_acc: 0.5033\n",
      "Epoch 221/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.8803e-04 - acc: 1.0000 - val_loss: 5.7136 - val_acc: 0.5034\n",
      "Epoch 222/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.8688e-04 - acc: 1.0000 - val_loss: 5.7148 - val_acc: 0.5031\n",
      "Epoch 223/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.8576e-04 - acc: 1.0000 - val_loss: 5.7159 - val_acc: 0.5033\n",
      "Epoch 224/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.8444e-04 - acc: 1.0000 - val_loss: 5.7171 - val_acc: 0.5033\n",
      "Epoch 225/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.8328e-04 - acc: 1.0000 - val_loss: 5.7183 - val_acc: 0.5032\n",
      "Epoch 226/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.8210e-04 - acc: 1.0000 - val_loss: 5.7193 - val_acc: 0.5031\n",
      "Epoch 227/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.8090e-04 - acc: 1.0000 - val_loss: 5.7205 - val_acc: 0.5035\n",
      "Epoch 228/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.7967e-04 - acc: 1.0000 - val_loss: 5.7219 - val_acc: 0.5033\n",
      "Epoch 229/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.7841e-04 - acc: 1.0000 - val_loss: 5.7228 - val_acc: 0.5032\n",
      "Epoch 230/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.7737e-04 - acc: 1.0000 - val_loss: 5.7239 - val_acc: 0.5032\n",
      "Epoch 231/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.7614e-04 - acc: 1.0000 - val_loss: 5.7251 - val_acc: 0.5032\n",
      "Epoch 232/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.7503e-04 - acc: 1.0000 - val_loss: 5.7262 - val_acc: 0.5033\n",
      "Epoch 233/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.7378e-04 - acc: 1.0000 - val_loss: 5.7272 - val_acc: 0.5033\n",
      "Epoch 234/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.7271e-04 - acc: 1.0000 - val_loss: 5.7285 - val_acc: 0.5031\n",
      "Epoch 235/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.7147e-04 - acc: 1.0000 - val_loss: 5.7294 - val_acc: 0.5031\n",
      "Epoch 236/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.7063e-04 - acc: 1.0000 - val_loss: 5.7306 - val_acc: 0.5034\n",
      "Epoch 237/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.6948e-04 - acc: 1.0000 - val_loss: 5.7316 - val_acc: 0.5033\n",
      "Epoch 238/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.6836e-04 - acc: 1.0000 - val_loss: 5.7328 - val_acc: 0.5030\n",
      "Epoch 239/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.6721e-04 - acc: 1.0000 - val_loss: 5.7339 - val_acc: 0.5031\n",
      "Epoch 240/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.6621e-04 - acc: 1.0000 - val_loss: 5.7350 - val_acc: 0.5031\n",
      "Epoch 241/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.6503e-04 - acc: 1.0000 - val_loss: 5.7361 - val_acc: 0.5030\n",
      "Epoch 242/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.6404e-04 - acc: 1.0000 - val_loss: 5.7373 - val_acc: 0.5030\n",
      "Epoch 243/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.6301e-04 - acc: 1.0000 - val_loss: 5.7382 - val_acc: 0.5030\n",
      "Epoch 244/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.6199e-04 - acc: 1.0000 - val_loss: 5.7393 - val_acc: 0.5030\n",
      "Epoch 245/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.6094e-04 - acc: 1.0000 - val_loss: 5.7403 - val_acc: 0.5029\n",
      "Epoch 246/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.5993e-04 - acc: 1.0000 - val_loss: 5.7413 - val_acc: 0.5031\n",
      "Epoch 247/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.5884e-04 - acc: 1.0000 - val_loss: 5.7424 - val_acc: 0.5030\n",
      "Epoch 248/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 2.5787e-04 - acc: 1.0000 - val_loss: 5.7434 - val_acc: 0.5031\n",
      "Epoch 249/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.5685e-04 - acc: 1.0000 - val_loss: 5.7443 - val_acc: 0.5031\n",
      "Epoch 250/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.5578e-04 - acc: 1.0000 - val_loss: 5.7454 - val_acc: 0.5030\n",
      "Epoch 251/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.5487e-04 - acc: 1.0000 - val_loss: 5.7465 - val_acc: 0.5029\n",
      "Epoch 252/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.5389e-04 - acc: 1.0000 - val_loss: 5.7474 - val_acc: 0.5029\n",
      "Epoch 253/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.5292e-04 - acc: 1.0000 - val_loss: 5.7485 - val_acc: 0.5028\n",
      "Epoch 254/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 2.5198e-04 - acc: 1.0000 - val_loss: 5.7495 - val_acc: 0.5032\n",
      "Epoch 255/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.5099e-04 - acc: 1.0000 - val_loss: 5.7503 - val_acc: 0.5030\n",
      "Epoch 256/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.5001e-04 - acc: 1.0000 - val_loss: 5.7512 - val_acc: 0.5030\n",
      "Epoch 257/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.4908e-04 - acc: 1.0000 - val_loss: 5.7524 - val_acc: 0.5030\n",
      "Epoch 258/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.4811e-04 - acc: 1.0000 - val_loss: 5.7534 - val_acc: 0.5031\n",
      "Epoch 259/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.4718e-04 - acc: 1.0000 - val_loss: 5.7545 - val_acc: 0.5029\n",
      "Epoch 260/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.4626e-04 - acc: 1.0000 - val_loss: 5.7556 - val_acc: 0.5030\n",
      "Epoch 261/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.4544e-04 - acc: 1.0000 - val_loss: 5.7566 - val_acc: 0.5028\n",
      "Epoch 262/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 2.4444e-04 - acc: 1.0000 - val_loss: 5.7573 - val_acc: 0.5029\n",
      "Epoch 263/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.4356e-04 - acc: 1.0000 - val_loss: 5.7584 - val_acc: 0.5031\n",
      "Epoch 264/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.4264e-04 - acc: 1.0000 - val_loss: 5.7594 - val_acc: 0.5030\n",
      "Epoch 265/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.4177e-04 - acc: 1.0000 - val_loss: 5.7603 - val_acc: 0.5030\n",
      "Epoch 266/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.4087e-04 - acc: 1.0000 - val_loss: 5.7613 - val_acc: 0.5029\n",
      "Epoch 267/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.3988e-04 - acc: 1.0000 - val_loss: 5.7624 - val_acc: 0.5030\n",
      "Epoch 268/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.3917e-04 - acc: 1.0000 - val_loss: 5.7633 - val_acc: 0.5028\n",
      "Epoch 269/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.3818e-04 - acc: 1.0000 - val_loss: 5.7643 - val_acc: 0.5030\n",
      "Epoch 270/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.3738e-04 - acc: 1.0000 - val_loss: 5.7653 - val_acc: 0.5028\n",
      "Epoch 271/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.3653e-04 - acc: 1.0000 - val_loss: 5.7662 - val_acc: 0.5031\n",
      "Epoch 272/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.3567e-04 - acc: 1.0000 - val_loss: 5.7672 - val_acc: 0.5031\n",
      "Epoch 273/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.3484e-04 - acc: 1.0000 - val_loss: 5.7681 - val_acc: 0.5031\n",
      "Epoch 274/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.3402e-04 - acc: 1.0000 - val_loss: 5.7688 - val_acc: 0.5029\n",
      "Epoch 275/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.3315e-04 - acc: 1.0000 - val_loss: 5.7699 - val_acc: 0.5029\n",
      "Epoch 276/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.3235e-04 - acc: 1.0000 - val_loss: 5.7709 - val_acc: 0.5031\n",
      "Epoch 277/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.3149e-04 - acc: 1.0000 - val_loss: 5.7717 - val_acc: 0.5032\n",
      "Epoch 278/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.3060e-04 - acc: 1.0000 - val_loss: 5.7727 - val_acc: 0.5032\n",
      "Epoch 279/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.2991e-04 - acc: 1.0000 - val_loss: 5.7738 - val_acc: 0.5031\n",
      "Epoch 280/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.2909e-04 - acc: 1.0000 - val_loss: 5.7746 - val_acc: 0.5031\n",
      "Epoch 281/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.2828e-04 - acc: 1.0000 - val_loss: 5.7753 - val_acc: 0.5032\n",
      "Epoch 282/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.2745e-04 - acc: 1.0000 - val_loss: 5.7761 - val_acc: 0.5031\n",
      "Epoch 283/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.2669e-04 - acc: 1.0000 - val_loss: 5.7770 - val_acc: 0.5031\n",
      "Epoch 284/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.2592e-04 - acc: 1.0000 - val_loss: 5.7781 - val_acc: 0.5032\n",
      "Epoch 285/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.2512e-04 - acc: 1.0000 - val_loss: 5.7791 - val_acc: 0.5031\n",
      "Epoch 286/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.2433e-04 - acc: 1.0000 - val_loss: 5.7799 - val_acc: 0.5033\n",
      "Epoch 287/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.2362e-04 - acc: 1.0000 - val_loss: 5.7805 - val_acc: 0.5034\n",
      "Epoch 288/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.2280e-04 - acc: 1.0000 - val_loss: 5.7815 - val_acc: 0.5033\n",
      "Epoch 289/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.2196e-04 - acc: 1.0000 - val_loss: 5.7825 - val_acc: 0.5033\n",
      "Epoch 290/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.2129e-04 - acc: 1.0000 - val_loss: 5.7834 - val_acc: 0.5033\n",
      "Epoch 291/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.2059e-04 - acc: 1.0000 - val_loss: 5.7841 - val_acc: 0.5034\n",
      "Epoch 292/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.1979e-04 - acc: 1.0000 - val_loss: 5.7850 - val_acc: 0.5035\n",
      "Epoch 293/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.1904e-04 - acc: 1.0000 - val_loss: 5.7858 - val_acc: 0.5035\n",
      "Epoch 294/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.1834e-04 - acc: 1.0000 - val_loss: 5.7867 - val_acc: 0.5035\n",
      "Epoch 295/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.1761e-04 - acc: 1.0000 - val_loss: 5.7876 - val_acc: 0.5033\n",
      "Epoch 296/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.1682e-04 - acc: 1.0000 - val_loss: 5.7884 - val_acc: 0.5035\n",
      "Epoch 297/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.1616e-04 - acc: 1.0000 - val_loss: 5.7893 - val_acc: 0.5035\n",
      "Epoch 298/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.1545e-04 - acc: 1.0000 - val_loss: 5.7902 - val_acc: 0.5035\n",
      "Epoch 299/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.1474e-04 - acc: 1.0000 - val_loss: 5.7911 - val_acc: 0.5034\n",
      "Epoch 300/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.1402e-04 - acc: 1.0000 - val_loss: 5.7918 - val_acc: 0.5033\n",
      "Epoch 301/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.1327e-04 - acc: 1.0000 - val_loss: 5.7925 - val_acc: 0.5034\n",
      "Epoch 302/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.1266e-04 - acc: 1.0000 - val_loss: 5.7935 - val_acc: 0.5034\n",
      "Epoch 303/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.1193e-04 - acc: 1.0000 - val_loss: 5.7943 - val_acc: 0.5034\n",
      "Epoch 304/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.1125e-04 - acc: 1.0000 - val_loss: 5.7950 - val_acc: 0.5035\n",
      "Epoch 305/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.1055e-04 - acc: 1.0000 - val_loss: 5.7958 - val_acc: 0.5035\n",
      "Epoch 306/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.0982e-04 - acc: 1.0000 - val_loss: 5.7967 - val_acc: 0.5035\n",
      "Epoch 307/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.0917e-04 - acc: 1.0000 - val_loss: 5.7975 - val_acc: 0.5034\n",
      "Epoch 308/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.0853e-04 - acc: 1.0000 - val_loss: 5.7982 - val_acc: 0.5035\n",
      "Epoch 309/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.0787e-04 - acc: 1.0000 - val_loss: 5.7990 - val_acc: 0.5036\n",
      "Epoch 310/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.0717e-04 - acc: 1.0000 - val_loss: 5.7998 - val_acc: 0.5035\n",
      "Epoch 311/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.0657e-04 - acc: 1.0000 - val_loss: 5.8007 - val_acc: 0.5036\n",
      "Epoch 312/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.0590e-04 - acc: 1.0000 - val_loss: 5.8015 - val_acc: 0.5035\n",
      "Epoch 313/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 2.0525e-04 - acc: 1.0000 - val_loss: 5.8024 - val_acc: 0.5035\n",
      "Epoch 314/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 2.0454e-04 - acc: 1.0000 - val_loss: 5.8032 - val_acc: 0.5036\n",
      "Epoch 315/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 2.0397e-04 - acc: 1.0000 - val_loss: 5.8041 - val_acc: 0.5036\n",
      "Epoch 316/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.0330e-04 - acc: 1.0000 - val_loss: 5.8048 - val_acc: 0.5035\n",
      "Epoch 317/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.0270e-04 - acc: 1.0000 - val_loss: 5.8054 - val_acc: 0.5036\n",
      "Epoch 318/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 2.0205e-04 - acc: 1.0000 - val_loss: 5.8063 - val_acc: 0.5036\n",
      "Epoch 319/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 2.0140e-04 - acc: 1.0000 - val_loss: 5.8071 - val_acc: 0.5034\n",
      "Epoch 320/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.0079e-04 - acc: 1.0000 - val_loss: 5.8080 - val_acc: 0.5035\n",
      "Epoch 321/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 2.0016e-04 - acc: 1.0000 - val_loss: 5.8086 - val_acc: 0.5036\n",
      "Epoch 322/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.9953e-04 - acc: 1.0000 - val_loss: 5.8092 - val_acc: 0.5034\n",
      "Epoch 323/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.9887e-04 - acc: 1.0000 - val_loss: 5.8102 - val_acc: 0.5036\n",
      "Epoch 324/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.9834e-04 - acc: 1.0000 - val_loss: 5.8110 - val_acc: 0.5037\n",
      "Epoch 325/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.9771e-04 - acc: 1.0000 - val_loss: 5.8118 - val_acc: 0.5037\n",
      "Epoch 326/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.9713e-04 - acc: 1.0000 - val_loss: 5.8126 - val_acc: 0.5037\n",
      "Epoch 327/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.9652e-04 - acc: 1.0000 - val_loss: 5.8135 - val_acc: 0.5037\n",
      "Epoch 328/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.9589e-04 - acc: 1.0000 - val_loss: 5.8141 - val_acc: 0.5035\n",
      "Epoch 329/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.9536e-04 - acc: 1.0000 - val_loss: 5.8149 - val_acc: 0.5036\n",
      "Epoch 330/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.9474e-04 - acc: 1.0000 - val_loss: 5.8155 - val_acc: 0.5037\n",
      "Epoch 331/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.9413e-04 - acc: 1.0000 - val_loss: 5.8163 - val_acc: 0.5036\n",
      "Epoch 332/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.9357e-04 - acc: 1.0000 - val_loss: 5.8171 - val_acc: 0.5037\n",
      "Epoch 333/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.9297e-04 - acc: 1.0000 - val_loss: 5.8178 - val_acc: 0.5036\n",
      "Epoch 334/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.9242e-04 - acc: 1.0000 - val_loss: 5.8186 - val_acc: 0.5037\n",
      "Epoch 335/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.9185e-04 - acc: 1.0000 - val_loss: 5.8194 - val_acc: 0.5037\n",
      "Epoch 336/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.9126e-04 - acc: 1.0000 - val_loss: 5.8201 - val_acc: 0.5037\n",
      "Epoch 337/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.9069e-04 - acc: 1.0000 - val_loss: 5.8208 - val_acc: 0.5036\n",
      "Epoch 338/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.9011e-04 - acc: 1.0000 - val_loss: 5.8215 - val_acc: 0.5036\n",
      "Epoch 339/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.8958e-04 - acc: 1.0000 - val_loss: 5.8223 - val_acc: 0.5037\n",
      "Epoch 340/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.8904e-04 - acc: 1.0000 - val_loss: 5.8229 - val_acc: 0.5037\n",
      "Epoch 341/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.8841e-04 - acc: 1.0000 - val_loss: 5.8237 - val_acc: 0.5038\n",
      "Epoch 342/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.8789e-04 - acc: 1.0000 - val_loss: 5.8244 - val_acc: 0.5037\n",
      "Epoch 343/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.8736e-04 - acc: 1.0000 - val_loss: 5.8252 - val_acc: 0.5037\n",
      "Epoch 344/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.8682e-04 - acc: 1.0000 - val_loss: 5.8259 - val_acc: 0.5037\n",
      "Epoch 345/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.8624e-04 - acc: 1.0000 - val_loss: 5.8267 - val_acc: 0.5037\n",
      "Epoch 346/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.8574e-04 - acc: 1.0000 - val_loss: 5.8274 - val_acc: 0.5037\n",
      "Epoch 347/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.8520e-04 - acc: 1.0000 - val_loss: 5.8280 - val_acc: 0.5035\n",
      "Epoch 348/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.8462e-04 - acc: 1.0000 - val_loss: 5.8287 - val_acc: 0.5036\n",
      "Epoch 349/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.8413e-04 - acc: 1.0000 - val_loss: 5.8294 - val_acc: 0.5035\n",
      "Epoch 350/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.8362e-04 - acc: 1.0000 - val_loss: 5.8301 - val_acc: 0.5035\n",
      "Epoch 351/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.8308e-04 - acc: 1.0000 - val_loss: 5.8310 - val_acc: 0.5036\n",
      "Epoch 352/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.8252e-04 - acc: 1.0000 - val_loss: 5.8316 - val_acc: 0.5037\n",
      "Epoch 353/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.8204e-04 - acc: 1.0000 - val_loss: 5.8324 - val_acc: 0.5037\n",
      "Epoch 354/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.8151e-04 - acc: 1.0000 - val_loss: 5.8330 - val_acc: 0.5037\n",
      "Epoch 355/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.8099e-04 - acc: 1.0000 - val_loss: 5.8336 - val_acc: 0.5036\n",
      "Epoch 356/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.8049e-04 - acc: 1.0000 - val_loss: 5.8344 - val_acc: 0.5036\n",
      "Epoch 357/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.7995e-04 - acc: 1.0000 - val_loss: 5.8352 - val_acc: 0.5036\n",
      "Epoch 358/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.7948e-04 - acc: 1.0000 - val_loss: 5.8359 - val_acc: 0.5037\n",
      "Epoch 359/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.7902e-04 - acc: 1.0000 - val_loss: 5.8366 - val_acc: 0.5038\n",
      "Epoch 360/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.7849e-04 - acc: 1.0000 - val_loss: 5.8371 - val_acc: 0.5037\n",
      "Epoch 361/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.7799e-04 - acc: 1.0000 - val_loss: 5.8379 - val_acc: 0.5037\n",
      "Epoch 362/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.7752e-04 - acc: 1.0000 - val_loss: 5.8385 - val_acc: 0.5035\n",
      "Epoch 363/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.7703e-04 - acc: 1.0000 - val_loss: 5.8391 - val_acc: 0.5036\n",
      "Epoch 364/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.7654e-04 - acc: 1.0000 - val_loss: 5.8398 - val_acc: 0.5037\n",
      "Epoch 365/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.7607e-04 - acc: 1.0000 - val_loss: 5.8404 - val_acc: 0.5037\n",
      "Epoch 366/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.7558e-04 - acc: 1.0000 - val_loss: 5.8412 - val_acc: 0.5036\n",
      "Epoch 367/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.7503e-04 - acc: 1.0000 - val_loss: 5.8419 - val_acc: 0.5037\n",
      "Epoch 368/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.7458e-04 - acc: 1.0000 - val_loss: 5.8425 - val_acc: 0.5037\n",
      "Epoch 369/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.7411e-04 - acc: 1.0000 - val_loss: 5.8432 - val_acc: 0.5036\n",
      "Epoch 370/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.7368e-04 - acc: 1.0000 - val_loss: 5.8439 - val_acc: 0.5037\n",
      "Epoch 371/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.7318e-04 - acc: 1.0000 - val_loss: 5.8444 - val_acc: 0.5038\n",
      "Epoch 372/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.7273e-04 - acc: 1.0000 - val_loss: 5.8453 - val_acc: 0.5037\n",
      "Epoch 373/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.7225e-04 - acc: 1.0000 - val_loss: 5.8459 - val_acc: 0.5038\n",
      "Epoch 374/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.7179e-04 - acc: 1.0000 - val_loss: 5.8464 - val_acc: 0.5037\n",
      "Epoch 375/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.7135e-04 - acc: 1.0000 - val_loss: 5.8472 - val_acc: 0.5038\n",
      "Epoch 376/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.7089e-04 - acc: 1.0000 - val_loss: 5.8478 - val_acc: 0.5036\n",
      "Epoch 377/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.7041e-04 - acc: 1.0000 - val_loss: 5.8485 - val_acc: 0.5037\n",
      "Epoch 378/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.6994e-04 - acc: 1.0000 - val_loss: 5.8491 - val_acc: 0.5037\n",
      "Epoch 379/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.6952e-04 - acc: 1.0000 - val_loss: 5.8498 - val_acc: 0.5036\n",
      "Epoch 380/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.6908e-04 - acc: 1.0000 - val_loss: 5.8504 - val_acc: 0.5037\n",
      "Epoch 381/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6861e-04 - acc: 1.0000 - val_loss: 5.8510 - val_acc: 0.5038\n",
      "Epoch 382/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.6818e-04 - acc: 1.0000 - val_loss: 5.8516 - val_acc: 0.5036\n",
      "Epoch 383/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6776e-04 - acc: 1.0000 - val_loss: 5.8523 - val_acc: 0.5036\n",
      "Epoch 384/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.6726e-04 - acc: 1.0000 - val_loss: 5.8529 - val_acc: 0.5036\n",
      "Epoch 385/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.6688e-04 - acc: 1.0000 - val_loss: 5.8536 - val_acc: 0.5035\n",
      "Epoch 386/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.6644e-04 - acc: 1.0000 - val_loss: 5.8542 - val_acc: 0.5036\n",
      "Epoch 387/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.6599e-04 - acc: 1.0000 - val_loss: 5.8549 - val_acc: 0.5035\n",
      "Epoch 388/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.6559e-04 - acc: 1.0000 - val_loss: 5.8555 - val_acc: 0.5034\n",
      "Epoch 389/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.6514e-04 - acc: 1.0000 - val_loss: 5.8560 - val_acc: 0.5036\n",
      "Epoch 390/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6472e-04 - acc: 1.0000 - val_loss: 5.8567 - val_acc: 0.5036\n",
      "Epoch 391/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.6427e-04 - acc: 1.0000 - val_loss: 5.8573 - val_acc: 0.5036\n",
      "Epoch 392/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.6386e-04 - acc: 1.0000 - val_loss: 5.8580 - val_acc: 0.5035\n",
      "Epoch 393/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6346e-04 - acc: 1.0000 - val_loss: 5.8585 - val_acc: 0.5036\n",
      "Epoch 394/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.6303e-04 - acc: 1.0000 - val_loss: 5.8592 - val_acc: 0.5036\n",
      "Epoch 395/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6263e-04 - acc: 1.0000 - val_loss: 5.8598 - val_acc: 0.5034\n",
      "Epoch 396/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6219e-04 - acc: 1.0000 - val_loss: 5.8604 - val_acc: 0.5037\n",
      "Epoch 397/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6179e-04 - acc: 1.0000 - val_loss: 5.8610 - val_acc: 0.5035\n",
      "Epoch 398/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.6138e-04 - acc: 1.0000 - val_loss: 5.8617 - val_acc: 0.5036\n",
      "Epoch 399/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6097e-04 - acc: 1.0000 - val_loss: 5.8622 - val_acc: 0.5034\n",
      "Epoch 400/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.6056e-04 - acc: 1.0000 - val_loss: 5.8628 - val_acc: 0.5036\n",
      "Epoch 401/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6018e-04 - acc: 1.0000 - val_loss: 5.8635 - val_acc: 0.5036\n",
      "Epoch 402/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.5976e-04 - acc: 1.0000 - val_loss: 5.8641 - val_acc: 0.5035\n",
      "Epoch 403/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.5935e-04 - acc: 1.0000 - val_loss: 5.8647 - val_acc: 0.5037\n",
      "Epoch 404/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.5897e-04 - acc: 1.0000 - val_loss: 5.8653 - val_acc: 0.5037\n",
      "Epoch 405/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.5857e-04 - acc: 1.0000 - val_loss: 5.8660 - val_acc: 0.5036\n",
      "Epoch 406/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.5817e-04 - acc: 1.0000 - val_loss: 5.8665 - val_acc: 0.5036\n",
      "Epoch 407/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.5777e-04 - acc: 1.0000 - val_loss: 5.8672 - val_acc: 0.5035\n",
      "Epoch 408/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.5737e-04 - acc: 1.0000 - val_loss: 5.8678 - val_acc: 0.5033\n",
      "Epoch 409/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.5701e-04 - acc: 1.0000 - val_loss: 5.8683 - val_acc: 0.5033\n",
      "Epoch 410/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.5658e-04 - acc: 1.0000 - val_loss: 5.8690 - val_acc: 0.5034\n",
      "Epoch 411/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.5621e-04 - acc: 1.0000 - val_loss: 5.8695 - val_acc: 0.5033\n",
      "Epoch 412/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.5586e-04 - acc: 1.0000 - val_loss: 5.8701 - val_acc: 0.5034\n",
      "Epoch 413/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.5545e-04 - acc: 1.0000 - val_loss: 5.8707 - val_acc: 0.5033\n",
      "Epoch 414/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.5506e-04 - acc: 1.0000 - val_loss: 5.8713 - val_acc: 0.5033\n",
      "Epoch 415/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.5466e-04 - acc: 1.0000 - val_loss: 5.8718 - val_acc: 0.5033\n",
      "Epoch 416/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.5430e-04 - acc: 1.0000 - val_loss: 5.8723 - val_acc: 0.5034\n",
      "Epoch 417/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.5395e-04 - acc: 1.0000 - val_loss: 5.8730 - val_acc: 0.5034\n",
      "Epoch 418/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.5357e-04 - acc: 1.0000 - val_loss: 5.8736 - val_acc: 0.5035\n",
      "Epoch 419/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.5322e-04 - acc: 1.0000 - val_loss: 5.8741 - val_acc: 0.5036\n",
      "Epoch 420/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.5283e-04 - acc: 1.0000 - val_loss: 5.8747 - val_acc: 0.5033\n",
      "Epoch 421/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.5247e-04 - acc: 1.0000 - val_loss: 5.8752 - val_acc: 0.5033\n",
      "Epoch 422/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.5212e-04 - acc: 1.0000 - val_loss: 5.8758 - val_acc: 0.5033\n",
      "Epoch 423/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.5173e-04 - acc: 1.0000 - val_loss: 5.8763 - val_acc: 0.5035\n",
      "Epoch 424/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.5139e-04 - acc: 1.0000 - val_loss: 5.8768 - val_acc: 0.5035\n",
      "Epoch 425/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.5102e-04 - acc: 1.0000 - val_loss: 5.8775 - val_acc: 0.5032\n",
      "Epoch 426/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.5067e-04 - acc: 1.0000 - val_loss: 5.8780 - val_acc: 0.5032\n",
      "Epoch 427/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.5030e-04 - acc: 1.0000 - val_loss: 5.8786 - val_acc: 0.5033\n",
      "Epoch 428/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4995e-04 - acc: 1.0000 - val_loss: 5.8791 - val_acc: 0.5033\n",
      "Epoch 429/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.4958e-04 - acc: 1.0000 - val_loss: 5.8798 - val_acc: 0.5033\n",
      "Epoch 430/500\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.4922e-04 - acc: 1.0000 - val_loss: 5.8803 - val_acc: 0.5034\n",
      "Epoch 431/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.4891e-04 - acc: 1.0000 - val_loss: 5.8809 - val_acc: 0.5034\n",
      "Epoch 432/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.4855e-04 - acc: 1.0000 - val_loss: 5.8814 - val_acc: 0.5035\n",
      "Epoch 433/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.4819e-04 - acc: 1.0000 - val_loss: 5.8819 - val_acc: 0.5034\n",
      "Epoch 434/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.4784e-04 - acc: 1.0000 - val_loss: 5.8824 - val_acc: 0.5035\n",
      "Epoch 435/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4750e-04 - acc: 1.0000 - val_loss: 5.8829 - val_acc: 0.5034\n",
      "Epoch 436/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.4717e-04 - acc: 1.0000 - val_loss: 5.8835 - val_acc: 0.5034\n",
      "Epoch 437/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.4683e-04 - acc: 1.0000 - val_loss: 5.8840 - val_acc: 0.5035\n",
      "Epoch 438/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.4647e-04 - acc: 1.0000 - val_loss: 5.8846 - val_acc: 0.5034\n",
      "Epoch 439/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.4615e-04 - acc: 1.0000 - val_loss: 5.8852 - val_acc: 0.5031\n",
      "Epoch 440/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4581e-04 - acc: 1.0000 - val_loss: 5.8858 - val_acc: 0.5034\n",
      "Epoch 441/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4547e-04 - acc: 1.0000 - val_loss: 5.8864 - val_acc: 0.5033\n",
      "Epoch 442/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4511e-04 - acc: 1.0000 - val_loss: 5.8868 - val_acc: 0.5033\n",
      "Epoch 443/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.4481e-04 - acc: 1.0000 - val_loss: 5.8874 - val_acc: 0.5031\n",
      "Epoch 444/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.4446e-04 - acc: 1.0000 - val_loss: 5.8879 - val_acc: 0.5032\n",
      "Epoch 445/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.4414e-04 - acc: 1.0000 - val_loss: 5.8884 - val_acc: 0.5035\n",
      "Epoch 446/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.4382e-04 - acc: 1.0000 - val_loss: 5.8889 - val_acc: 0.5032\n",
      "Epoch 447/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.4350e-04 - acc: 1.0000 - val_loss: 5.8896 - val_acc: 0.5033\n",
      "Epoch 448/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.4315e-04 - acc: 1.0000 - val_loss: 5.8900 - val_acc: 0.5032\n",
      "Epoch 449/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4286e-04 - acc: 1.0000 - val_loss: 5.8906 - val_acc: 0.5032\n",
      "Epoch 450/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4253e-04 - acc: 1.0000 - val_loss: 5.8911 - val_acc: 0.5033\n",
      "Epoch 451/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4219e-04 - acc: 1.0000 - val_loss: 5.8916 - val_acc: 0.5033\n",
      "Epoch 452/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4189e-04 - acc: 1.0000 - val_loss: 5.8921 - val_acc: 0.5033\n",
      "Epoch 453/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.4156e-04 - acc: 1.0000 - val_loss: 5.8926 - val_acc: 0.5033\n",
      "Epoch 454/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.4125e-04 - acc: 1.0000 - val_loss: 5.8931 - val_acc: 0.5033\n",
      "Epoch 455/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.4093e-04 - acc: 1.0000 - val_loss: 5.8936 - val_acc: 0.5033\n",
      "Epoch 456/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.4060e-04 - acc: 1.0000 - val_loss: 5.8941 - val_acc: 0.5034\n",
      "Epoch 457/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.4031e-04 - acc: 1.0000 - val_loss: 5.8946 - val_acc: 0.5033\n",
      "Epoch 458/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.4000e-04 - acc: 1.0000 - val_loss: 5.8951 - val_acc: 0.5033\n",
      "Epoch 459/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3967e-04 - acc: 1.0000 - val_loss: 5.8956 - val_acc: 0.5032\n",
      "Epoch 460/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.3938e-04 - acc: 1.0000 - val_loss: 5.8961 - val_acc: 0.5033\n",
      "Epoch 461/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.3907e-04 - acc: 1.0000 - val_loss: 5.8966 - val_acc: 0.5033\n",
      "Epoch 462/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3876e-04 - acc: 1.0000 - val_loss: 5.8971 - val_acc: 0.5033\n",
      "Epoch 463/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3843e-04 - acc: 1.0000 - val_loss: 5.8977 - val_acc: 0.5034\n",
      "Epoch 464/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3814e-04 - acc: 1.0000 - val_loss: 5.8982 - val_acc: 0.5032\n",
      "Epoch 465/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.3782e-04 - acc: 1.0000 - val_loss: 5.8987 - val_acc: 0.5032\n",
      "Epoch 466/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.3755e-04 - acc: 1.0000 - val_loss: 5.8993 - val_acc: 0.5033\n",
      "Epoch 467/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3724e-04 - acc: 1.0000 - val_loss: 5.8997 - val_acc: 0.5033\n",
      "Epoch 468/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3694e-04 - acc: 1.0000 - val_loss: 5.9003 - val_acc: 0.5032\n",
      "Epoch 469/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3663e-04 - acc: 1.0000 - val_loss: 5.9008 - val_acc: 0.5033\n",
      "Epoch 470/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.3634e-04 - acc: 1.0000 - val_loss: 5.9013 - val_acc: 0.5032\n",
      "Epoch 471/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.3607e-04 - acc: 1.0000 - val_loss: 5.9018 - val_acc: 0.5033\n",
      "Epoch 472/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3576e-04 - acc: 1.0000 - val_loss: 5.9023 - val_acc: 0.5033\n",
      "Epoch 473/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.3546e-04 - acc: 1.0000 - val_loss: 5.9029 - val_acc: 0.5034\n",
      "Epoch 474/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3518e-04 - acc: 1.0000 - val_loss: 5.9033 - val_acc: 0.5034\n",
      "Epoch 475/500\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 1.3487e-04 - acc: 1.0000 - val_loss: 5.9038 - val_acc: 0.5033\n",
      "Epoch 476/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3460e-04 - acc: 1.0000 - val_loss: 5.9043 - val_acc: 0.5034\n",
      "Epoch 477/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3430e-04 - acc: 1.0000 - val_loss: 5.9048 - val_acc: 0.5034\n",
      "Epoch 478/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.3401e-04 - acc: 1.0000 - val_loss: 5.9052 - val_acc: 0.5035\n",
      "Epoch 479/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.3373e-04 - acc: 1.0000 - val_loss: 5.9056 - val_acc: 0.5033\n",
      "Epoch 480/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.3346e-04 - acc: 1.0000 - val_loss: 5.9062 - val_acc: 0.5033\n",
      "Epoch 481/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.3316e-04 - acc: 1.0000 - val_loss: 5.9067 - val_acc: 0.5033\n",
      "Epoch 482/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.3287e-04 - acc: 1.0000 - val_loss: 5.9072 - val_acc: 0.5033\n",
      "Epoch 483/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.3261e-04 - acc: 1.0000 - val_loss: 5.9077 - val_acc: 0.5034\n",
      "Epoch 484/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.3231e-04 - acc: 1.0000 - val_loss: 5.9082 - val_acc: 0.5034\n",
      "Epoch 485/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3206e-04 - acc: 1.0000 - val_loss: 5.9087 - val_acc: 0.5033\n",
      "Epoch 486/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3177e-04 - acc: 1.0000 - val_loss: 5.9092 - val_acc: 0.5032\n",
      "Epoch 487/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.3150e-04 - acc: 1.0000 - val_loss: 5.9096 - val_acc: 0.5033\n",
      "Epoch 488/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3122e-04 - acc: 1.0000 - val_loss: 5.9100 - val_acc: 0.5032\n",
      "Epoch 489/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.3094e-04 - acc: 1.0000 - val_loss: 5.9105 - val_acc: 0.5032\n",
      "Epoch 490/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.3067e-04 - acc: 1.0000 - val_loss: 5.9110 - val_acc: 0.5033\n",
      "Epoch 491/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.3038e-04 - acc: 1.0000 - val_loss: 5.9115 - val_acc: 0.5033\n",
      "Epoch 492/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.3013e-04 - acc: 1.0000 - val_loss: 5.9119 - val_acc: 0.5034\n",
      "Epoch 493/500\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 1.2985e-04 - acc: 1.0000 - val_loss: 5.9125 - val_acc: 0.5034\n",
      "Epoch 494/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.2957e-04 - acc: 1.0000 - val_loss: 5.9129 - val_acc: 0.5034\n",
      "Epoch 495/500\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 1.2929e-04 - acc: 1.0000 - val_loss: 5.9134 - val_acc: 0.5034\n",
      "Epoch 496/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.2905e-04 - acc: 1.0000 - val_loss: 5.9138 - val_acc: 0.5034\n",
      "Epoch 497/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.2876e-04 - acc: 1.0000 - val_loss: 5.9143 - val_acc: 0.5034\n",
      "Epoch 498/500\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.2852e-04 - acc: 1.0000 - val_loss: 5.9148 - val_acc: 0.5033\n",
      "Epoch 499/500\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.2824e-04 - acc: 1.0000 - val_loss: 5.9154 - val_acc: 0.5034\n",
      "Epoch 500/500\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.2799e-04 - acc: 1.0000 - val_loss: 5.9158 - val_acc: 0.5034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22149a72e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "設定要訓練的 Epoch 數\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2115,
     "status": "ok",
     "timestamp": 1574579495534,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "cO9fXRLoNMds",
    "outputId": "69ede0eb-7ef6-4859-bf41-65c14d163b72"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np6AWEQnc/wfNAQIf5bOgigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCJCgS4iEhEKdBGRiPj/D+NveAR+3FwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 以視覺畫方式檢視訓練過程\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day077_HW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
